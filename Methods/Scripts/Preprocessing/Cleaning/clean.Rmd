---
title: "Cleaning social media data"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, warning = FALSE)
```

## Reddit datasets

```{r}
rm(list = ls())

# Run script to create the reddit subsets
source("reddit_subsets.R", local = knitr::knit_global())
```


## Cleaning: Stages 1a + b.
a:
* Remove useless columns
* Done in python scripts (Reddit/main and Twitter/main)

b: 
* Remove any anomalies/useless posts missed by filters (e.g. blanks/removed/NaN, etc.)
* All lower-case.
* Tokenize
* Noise removal (punctuation, special characters, stopwords).

```{r}
# Load functions to clean sm data.
source("cleaning_funcs.R", local = knitr::knit_global())
```


```{r}
# Load data
reddit_emp_1 <- load_data('Reddit', 'Employment', 1)
reddit_emp_2 <- load_data('Reddit', 'Employment', 2)
reddit_emp_3 <- load_data('Reddit', 'Employment', 3)
reddit_emp_4 <- load_data('Reddit', 'Employment', 4)
```

```{r}
# Get all dates in the right format
reddit_emp_1 <- change_dates(reddit_emp_1)
reddit_emp_2 <- change_dates(reddit_emp_2)
reddit_emp_3 <- change_dates(reddit_emp_3)
reddit_emp_4 <- change_dates(reddit_emp_4)
```

```{r}
# Cleaning: stage 1b
```


