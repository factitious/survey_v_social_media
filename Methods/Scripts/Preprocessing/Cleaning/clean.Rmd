---
title: "Cleaning social media data"
output: html_notebook
---

```{r}
knitr::opts_chunk$set(echo = TRUE, include = TRUE, warning = FALSE)
```

## Reddit datasets

```{r}
rm(list = ls())

# Run script to create the reddit subsets
# source("reddit_subsets.R", local = knitr::knit_global())
```


## Cleaning: Stages 1a + b.
a:
* Remove useless columns
* Done in python scripts (Reddit/main and Twitter/main)

b: 
* Remove any anomalies/useless posts missed by filters (e.g. blanks/removed/NaN, etc.)
* All lower-case.
* Tokenize
* Noise removal (punctuation, special characters, stopwords).

```{r}
# Load functions to clean sm data.
source("cleaning_funcs.R", local = knitr::knit_global())
```


```{r}
# Load data
reddit_emp_1 <- load_data('Reddit', 'Employment', 1)
reddit_emp_2 <- load_data('Reddit', 'Employment', 2)
reddit_emp_3 <- load_data('Reddit', 'Employment', 3)
reddit_emp_4 <- load_data('Reddit', 'Employment', 4)
```

```{r}
# Cleaning: stage 1b
reddit_emp_1_c1b <- clean_stage1b(reddit_emp_1, 'Reddit')
reddit_emp_2_c1b <- clean_stage1b(reddit_emp_2, 'Reddit')
reddit_emp_3_c1b <- clean_stage1b(reddit_emp_3, 'Reddit')
reddit_emp_4_c1b <- clean_stage1b(reddit_emp_4, 'Reddit')

save_1b(reddit_emp_1_c1b, 'Reddit', 'Employment', 1)
save_1b(reddit_emp_2_c1b, 'Reddit', 'Employment', 2)
save_1b(reddit_emp_3_c1b, 'Reddit', 'Employment', 3)
save_1b(reddit_emp_4_c1b, 'Reddit', 'Employment', 4)
```

```{r}
twitter_emp_1 <- load_data('Twitter', 'Employment', 1)
twitter_emp_1_c1b <- clean_stage1b(twitter_emp_1, 'Twitter')
save_1b(twitter_emp_1_c1b, 'Twitter', 'Employment', 1)
```

