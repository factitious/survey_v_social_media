{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently getting:\n",
    "\n",
    ">~/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/requests/models.py in generate()\n",
    "    754                         yield chunk\n",
    "    755                 except ProtocolError as e:\n",
    "--> 756                     raise ChunkedEncodingError(e)\n",
    "    757                 except DecodeError as e:\n",
    "    758                     raise ContentDecodingError(e)\n",
    ">\n",
    "> ChunkedEncodingError: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read))\n",
    "\n",
    "Potential solutions:\n",
    "\n",
    "* https://www.programmersought.com/article/30503823121/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit import RedditData, RedditSubmissions, RedditComments, RedditSubComments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 525\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 522\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n"
     ]
    }
   ],
   "source": [
    "# emp_submissions = RedditSubmissions('Employment')\n",
    "# emp_submissions.get_one_week(0)\n",
    "# emp_submissions.export_one_week()\n",
    "\n",
    "# Get ids to pass to RedditComments\n",
    "# emp_sub_ids = emp_submissions.all_data[emp_submissions.current_week]['id']\n",
    "\n",
    "\n",
    "# vacc_submissions = RedditSubmissions('Vaccination')\n",
    "# vacc_submissions.get_one_week(0)\n",
    "# vacc_submissions.export_one_week()\n",
    "\n",
    "# Get ids to pass to RedditComments\n",
    "# vacc_sub_ids = vacc_submissions.all_data[vacc_submissions.current_week]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emp_comments_q = RedditComments('Employment')\n",
    "# emp_comments_q.get_one_week(0)\n",
    "# emp_comments_q.export_one_week()\n",
    "\n",
    "# vacc_comments_q = RedditComments('Vaccination')\n",
    "# vacc_comments_q.get_one_week(0)\n",
    "# vacc_comments_q.export_one_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = emp_submissions.all_data['2020-10-19']\n",
    "# df2 = vacc_submissions.all_data['2020-10-19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,logs = RedditData.load_one_week(\n",
    "                topic = 'Employment',\n",
    "                week_num = 0,\n",
    "                post_type = 'Submissions',\n",
    "                df_only = False\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ids = RedditData.get_ids(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = RedditData.id_chunks(sub_ids, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sub_comments = RedditSubComments(\n",
    "                        topic='Employment',\n",
    "                        sub_ids=sub_ids, \n",
    "                        chunk_size=200)\n",
    "emp_sub_comments.get_sub_comments(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subID = emp_sub_comments.all_data[emp_sub_comments.current_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>created</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweden has more billionaires per capita than t...</td>\n",
       "      <td>1603670397</td>\n",
       "      <td>ga48n6p</td>\n",
       "      <td>t3_ji1vw8</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_ga47jnj</td>\n",
       "      <td>/r/EnoughCommieSpam/comments/ji1vw8/yeah_billi...</td>\n",
       "      <td>1603676324</td>\n",
       "      <td>2</td>\n",
       "      <td>EnoughCommieSpam</td>\n",
       "      <td>t5_3fblz</td>\n",
       "      <td>1.603667e+09</td>\n",
       "      <td>2020-10-25 23:59:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1603670372</td>\n",
       "      <td>ga48ln7</td>\n",
       "      <td>t3_ji3voe</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ji3voe</td>\n",
       "      <td>/r/portlandme/comments/ji3voe/is_portland_a_pr...</td>\n",
       "      <td>1603676302</td>\n",
       "      <td>5</td>\n",
       "      <td>portlandme</td>\n",
       "      <td>t5_2t1eh</td>\n",
       "      <td>1.603667e+09</td>\n",
       "      <td>2020-10-25 23:59:32+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California is the easiest place to be homeless</td>\n",
       "      <td>1603670369</td>\n",
       "      <td>ga48lim</td>\n",
       "      <td>t3_ji40kr</td>\n",
       "      <td>False</td>\n",
       "      <td>t3_ji40kr</td>\n",
       "      <td>/r/homeless/comments/ji40kr/easiest_places_to_...</td>\n",
       "      <td>1603676300</td>\n",
       "      <td>3</td>\n",
       "      <td>homeless</td>\n",
       "      <td>t5_2qtcb</td>\n",
       "      <td>1.603667e+09</td>\n",
       "      <td>2020-10-25 23:59:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah that’s literally never been a thing until...</td>\n",
       "      <td>1603670349</td>\n",
       "      <td>ga48kbk</td>\n",
       "      <td>t3_ji0pom</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_ga3qp8h</td>\n",
       "      <td>/r/recruitinghell/comments/ji0pom/reporting_jo...</td>\n",
       "      <td>1603676283</td>\n",
       "      <td>28</td>\n",
       "      <td>recruitinghell</td>\n",
       "      <td>t5_3bwcw</td>\n",
       "      <td>1.603667e+09</td>\n",
       "      <td>2020-10-25 23:59:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&amp;gt; So, I'd prefer to ~~keep this discussion ...</td>\n",
       "      <td>1603670319</td>\n",
       "      <td>ga48ifg</td>\n",
       "      <td>t3_ji2vcb</td>\n",
       "      <td>False</td>\n",
       "      <td>t1_ga4212o</td>\n",
       "      <td>/r/newzealand/comments/ji2vcb/are_fruit_orchar...</td>\n",
       "      <td>1603676256</td>\n",
       "      <td>1</td>\n",
       "      <td>newzealand</td>\n",
       "      <td>t5_2qhma</td>\n",
       "      <td>1.603667e+09</td>\n",
       "      <td>2020-10-25 23:58:39+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  created_utc       id  \\\n",
       "0  Sweden has more billionaires per capita than t...   1603670397  ga48n6p   \n",
       "1                                                Yes   1603670372  ga48ln7   \n",
       "2     California is the easiest place to be homeless   1603670369  ga48lim   \n",
       "3  Yeah that’s literally never been a thing until...   1603670349  ga48kbk   \n",
       "4  &gt; So, I'd prefer to ~~keep this discussion ...   1603670319  ga48ifg   \n",
       "\n",
       "     link_id  locked   parent_id  \\\n",
       "0  t3_ji1vw8   False  t1_ga47jnj   \n",
       "1  t3_ji3voe   False   t3_ji3voe   \n",
       "2  t3_ji40kr   False   t3_ji40kr   \n",
       "3  t3_ji0pom   False  t1_ga3qp8h   \n",
       "4  t3_ji2vcb   False  t1_ga4212o   \n",
       "\n",
       "                                           permalink  retrieved_on  score  \\\n",
       "0  /r/EnoughCommieSpam/comments/ji1vw8/yeah_billi...    1603676324      2   \n",
       "1  /r/portlandme/comments/ji3voe/is_portland_a_pr...    1603676302      5   \n",
       "2  /r/homeless/comments/ji40kr/easiest_places_to_...    1603676300      3   \n",
       "3  /r/recruitinghell/comments/ji0pom/reporting_jo...    1603676283     28   \n",
       "4  /r/newzealand/comments/ji2vcb/are_fruit_orchar...    1603676256      1   \n",
       "\n",
       "          subreddit subreddit_id       created                      date  \n",
       "0  EnoughCommieSpam     t5_3fblz  1.603667e+09 2020-10-25 23:59:57+00:00  \n",
       "1        portlandme     t5_2t1eh  1.603667e+09 2020-10-25 23:59:32+00:00  \n",
       "2          homeless     t5_2qtcb  1.603667e+09 2020-10-25 23:59:29+00:00  \n",
       "3    recruitinghell     t5_3bwcw  1.603667e+09 2020-10-25 23:59:09+00:00  \n",
       "4        newzealand     t5_2qhma  1.603667e+09 2020-10-25 23:58:39+00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_ids = [x.split('_')[1] for x in df_subID['link_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99532\n",
      "5969\n"
     ]
    }
   ],
   "source": [
    "print(len(comm_ids))\n",
    "print(len(np.unique(comm_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6061\n",
      "6061\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_ids))\n",
    "print(len(np.unique(sub_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sub_ids) - set(np.unique(comm_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19     6 months of HARD WORK will put you ahead 5 yea...\n",
       "47                                                What ?\n",
       "125    Just visit @my user name. It’s there and I’m t...\n",
       "134    Set a Stop Loss on all your investments to pro...\n",
       "150    Hey intellectually stunted. It’s actually not....\n",
       "                             ...                        \n",
       "701    True, though by not voting you just sidestep e...\n",
       "726    Sorry to see that, this is one reason why I do...\n",
       "938    \\nIf you or someone you know is contemplating ...\n",
       "986                               Get in the kitchen LOL\n",
       "994                    You’re 14, stop swearing so much.\n",
       "Name: body, Length: 798, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subID['body'][df_subID['score'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df_subID['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_subID['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5465980790097658"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df_subID['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_subID['score'][df_subID['score'] > 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['score'][df['score'] > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'search_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-668acc9de430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mweek_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpost_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SubComments'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     df_only = False)\n\u001b[0m",
      "\u001b[0;32m/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Reddit/reddit.py\u001b[0m in \u001b[0;36mload_one_week\u001b[0;34m(cls, topic, week_num, post_type, df_only)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpost_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SubComments'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRedditComments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mweek_start_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrange\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweek_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'search_ids'"
     ]
    }
   ],
   "source": [
    "df_vacc_sub, log__vacc_sub = RedditData.load_one_week(\n",
    "    topic = 'Vaccination', \n",
    "    week_num = 0,\n",
    "    post_type = 'SubComments',\n",
    "    df_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_ids = df_vacc_sub['link_id']\n",
    "comm_ids = [x.split('_')[1] for x in comm_ids]\n",
    "sub_ids = df_load['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12909"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sub_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2939"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(comm_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the comm_ids in the sub_ids\n",
    "set(comm_ids) == set(sub_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(comm_ids) - set(sub_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employment_submissions = RedditSubmissions('Employment')\n",
    "# start_week = 0\n",
    "# end_week = 2\n",
    "\n",
    "\n",
    "# for week_num in range(start_week, end_week+1,1):\n",
    "    \n",
    "#     try:\n",
    "#         employment_submissions.get_one_week(week_num)\n",
    "#     except:\n",
    "#         print(\"Failed to get week #{}\".format(week_num))\n",
    "#         continue\n",
    "        \n",
    "#     employment_submissions.export_one_week()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(df):\n",
    "    \n",
    "    ids = df[df['num_comments']>2]['id']\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def id_chunks(ids, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(ids), n):\n",
    "        yield ids[i:i + n]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = get_ids(emp_submissions.all_data[emp_submissions.current_week])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = id_chunks(ids,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3970    jgrysz\n",
       "3971    jgrys3\n",
       "3972    jgry2h\n",
       "3975    jgrwkm\n",
       "3976    jgrwfj\n",
       "         ...  \n",
       "6102    jg46wj\n",
       "6105    jg467i\n",
       "6106    jg45v4\n",
       "6108    jg455q\n",
       "6109    jg4555\n",
       "Name: id, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "for ls in chunks:\n",
    "    print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_comments(ids, chunk_size, week):\n",
    "    \n",
    "    chunks = id_chunks(ids,chunk_size)\n",
    "    n_chunk = 0\n",
    "    \n",
    "    for chunk in chunks:\n",
    "    \n",
    "        current_sub = RedditComments(\n",
    "            'Employment', \n",
    "            search_ids = True,\n",
    "            ids = chunk)\n",
    "\n",
    "        current_sub.get_one_week(week)\n",
    "\n",
    "\n",
    "        if n_chunk == 0:\n",
    "            all_data = current_sub.all_data[current_sub.current_week]\n",
    "            all_logs = current_sub.logs[current_sub.current_week]\n",
    "\n",
    "        else:\n",
    "            all_data = pd.concat(all_data,current_sub.all_data[current_sub.current_week])\n",
    "            all_logs.update({\n",
    "\n",
    "                'mostRecent': max(all_logs['mostRecent'],\n",
    "                                  current_sub.logs[self.current_week]['mostRecent'])\n",
    "                'oldest': min(all_logs['oldest'],\n",
    "                                  current_sub.logs[self.current_week]['oldest'])\n",
    "                'periodCovered': max(['periodCovered'],\n",
    "                                  current_sub.logs[self.current_week]['periodCovered'])\n",
    "                'total': all_logs['total'] + current_sub.logs[self.current_week]['total']\n",
    "                'totalOverall': all_logs['totalOverall'] + \\\n",
    "                                current_sub.logs[self.current_week]['totalOverall']\n",
    "                'timeTaken': all_logs['timeTaken'] + \\\n",
    "                             current_sub.logs[self.current_week]['timeTaken']\n",
    "                'timeTakenTotal': all_logs['timeTakenTotal'] + \\\n",
    "                             current_sub.logs[self.current_week]['timeTakenTotal']\n",
    "            })\n",
    "            \n",
    "        n_chunk += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditScrapper",
   "language": "python",
   "name": "redditscrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
