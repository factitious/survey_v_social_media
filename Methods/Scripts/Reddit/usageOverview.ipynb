{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.0.7-py2.py3-none-any.whl (243 kB)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from psaw import PushshiftAPI\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "api = PushshiftAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Details on what this query actually does below.\n",
    "# # Here using it to figure out what some of the fields are.\n",
    "\n",
    "# start_time = int(datetime(2021, 6, 7).timestamp())\n",
    "# end_time = int(datetime(2021, 6, 14).timestamp())\n",
    "\n",
    "# api_request_generator = api.search_submissions(q='(jobs | employment)',\n",
    "#                                               after = start_time,\n",
    "#                                               before = end_time)\n",
    "\n",
    "# sub_recent = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "# sub_recent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_awardings\n",
      "allow_live_comments\n",
      "author\n",
      "author_flair_css_class\n",
      "author_flair_richtext\n",
      "author_flair_text\n",
      "author_flair_type\n",
      "author_fullname\n",
      "author_patreon_flair\n",
      "author_premium\n",
      "awarders\n",
      "can_mod_post\n",
      "contest_mode\n",
      "created_utc\n",
      "domain\n",
      "full_link\n",
      "gildings\n",
      "id\n",
      "is_created_from_ads_ui\n",
      "is_crosspostable\n",
      "is_meta\n",
      "is_original_content\n",
      "is_reddit_media_domain\n",
      "is_robot_indexable\n",
      "is_self\n",
      "is_video\n",
      "link_flair_background_color\n",
      "link_flair_css_class\n",
      "link_flair_richtext\n",
      "link_flair_template_id\n",
      "link_flair_text\n",
      "link_flair_text_color\n",
      "link_flair_type\n",
      "locked\n",
      "media_only\n",
      "no_follow\n",
      "num_comments\n",
      "num_crossposts\n",
      "over_18\n",
      "parent_whitelist_status\n",
      "permalink\n",
      "pinned\n",
      "pwls\n",
      "retrieved_on\n",
      "score\n",
      "selftext\n",
      "send_replies\n",
      "spoiler\n",
      "stickied\n",
      "subreddit\n",
      "subreddit_id\n",
      "subreddit_subscribers\n",
      "subreddit_type\n",
      "thumbnail\n",
      "title\n",
      "total_awards_received\n",
      "treatment_tags\n",
      "upvote_ratio\n",
      "url\n",
      "whitelist_status\n",
      "wls\n",
      "created\n",
      "removed_by_category\n",
      "suggested_sort\n",
      "post_hint\n",
      "preview\n",
      "edited\n",
      "url_overridden_by_dest\n",
      "author_flair_background_color\n",
      "author_flair_template_id\n",
      "author_flair_text_color\n",
      "thumbnail_height\n",
      "thumbnail_width\n",
      "media_metadata\n",
      "banned_by\n",
      "crosspost_parent\n",
      "crosspost_parent_list\n",
      "media\n",
      "media_embed\n",
      "secure_media\n",
      "secure_media_embed\n",
      "discussion_type\n",
      "gilded\n",
      "poll_data\n",
      "distinguished\n",
      "gallery_data\n",
      "is_gallery\n",
      "collections\n",
      "author_cakeday\n",
      "content_categories\n",
      "event_end\n",
      "event_is_live\n",
      "event_start\n",
      "author_id\n",
      "call_to_action\n",
      "domain_override\n",
      "events\n",
      "eventsOnRender\n",
      "href_url\n",
      "is_blank\n",
      "mobile_ad_url\n",
      "outbound_link\n",
      "promoted\n",
      "show_media\n",
      "third_party_trackers\n"
     ]
    }
   ],
   "source": [
    "for f in sub_recent.columns:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping:\n",
    "\n",
    "\n",
    "* created_utc\n",
    "* id\n",
    "* num_comments\n",
    "* num_crossposts\n",
    "* retrieved_on\n",
    "* score\n",
    "* selftext\n",
    "* subreddit\n",
    "* subreddit_id\n",
    "* title\n",
    "\n",
    "Not quite sure what these are and whether we should filter (the search) on these:\n",
    "is_created_from_ads_ui\n",
    "is_crosspostable\n",
    "is_meta\n",
    "is_original_content\n",
    "is_reddit_media_domain\n",
    "is_robot_indexable\n",
    "is_self\n",
    "is_video\n",
    "media_only\n",
    "over_18\n",
    "\n",
    "subreddit_subscribers\n",
    "subreddit_type\n",
    "upvote_ratio\n",
    "created\n",
    "\n",
    "domain\n",
    "full_link vs permalink vs url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         124847\n",
       "1        2532943\n",
       "2         248844\n",
       "3        1718599\n",
       "4        3080701\n",
       "          ...   \n",
       "16400          0\n",
       "16401      78373\n",
       "16402          0\n",
       "16403          0\n",
       "16404          0\n",
       "Name: subreddit_subscribers, Length: 16405, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_recent['subreddit_subscribers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dates right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyPeriods = pd.read_excel('/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Surveys/table_details/surveyPeriods.xlsx', sheet_name='AI+HPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The actual query needs to be made with a utc timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_utc_timestamp(date_ts):\n",
    "    '''\n",
    "\n",
    "    Parameters:\n",
    "        date_ts (Timestamp): \n",
    "\n",
    "    Returns:\n",
    "        date (datetime): A datetime object  \n",
    "    '''\n",
    "\n",
    "    dateDT = date_ts.replace(tzinfo = timezone.utc).timestamp()\n",
    "    \n",
    "    return dateDT\n",
    "\n",
    "\n",
    "def weekFromDay(day):\n",
    "    '''\n",
    "    Work the week starting and ending dates given any date.\n",
    "    Params:\n",
    "        day (datetime): Can be a Timestamp (pandas/numpy object) or a datetime.datetime object.\n",
    "\n",
    "    Returns: \n",
    "        weekStart (Timestamp): The date corresponding to the start (i.e. Monday) of the date specified by *day* param.\n",
    "        weekEnd (Timestamp): The date corresponding to the end (i.e. Sunday) of the date specified by *day* param.\n",
    "    '''\n",
    "\n",
    "    weekStart = day - timedelta(days=day.weekday())\n",
    "    weekEnd = weekStart + timedelta(days=6)\n",
    "\n",
    "    return weekStart.strftime('%Y-%m-%d'), weekEnd.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def nextMonday(date):\n",
    "#     date = toDatetime(date)\n",
    "\n",
    "    date_dt = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "    nextM = date_dt + timedelta(days=-date_dt.weekday(), weeks=1)\n",
    "\n",
    "    return nextM\n",
    "\n",
    "def surveyDates(surveyPeriods):\n",
    "\n",
    "\n",
    "    # Load survey periods\n",
    "#     surveyPeriods = pd.read_excel('/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Surveys/table_details/surveyPeriods.xlsx', sheet_name='AI+HPS')\n",
    "\n",
    "    # Generate tuple of week start and end dates based on the collection dates in the Axios/Ipsos survey. \n",
    "    AI_weeks = [weekFromDay(date) for date in surveyPeriods['A_I_start_date']]\n",
    "\n",
    "\n",
    "    # Get first monday and last sunday from the A/I data collection periods\n",
    "    firstDate,_ = weekFromDay(surveyPeriods['A_I_start_date'][0])\n",
    "    _, lastDate = weekFromDay(surveyPeriods['A_I_start_date'].iloc[-1])\n",
    "\n",
    "    # Create data ranges for all mondays/sundays starting with the first one covered in A/I.\n",
    "    mondays = pd.date_range(firstDate, lastDate, freq='W-MON')\n",
    "    leading_mondays = pd.date_range(nextMonday(firstDate), nextMonday(lastDate), freq='W-MON')\n",
    "\n",
    "    # Get strings\n",
    "    mondays_str = mondays.strftime('%Y-%m-%d')\n",
    "    leading_mondays_str = leading_mondays.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Saving all the results in a tuple\n",
    "    all_weeks_utc = [(to_utc_timestamp(m), to_utc_timestamp(s)) for m, s in zip(mondays, leading_mondays)]\n",
    "    all_weeks_str = [(m, s) for m, s in zip(mondays_str, leading_mondays_str)]\n",
    "    \n",
    "    return all_weeks_utc, all_weeks_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weeks_utc, all_weeks_str = surveyDates(surveyPeriods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1603065600.0, 1603670400.0),\n",
       " (1603670400.0, 1604275200.0),\n",
       " (1604275200.0, 1604880000.0),\n",
       " (1604880000.0, 1605484800.0),\n",
       " (1605484800.0, 1606089600.0),\n",
       " (1606089600.0, 1606694400.0),\n",
       " (1606694400.0, 1607299200.0),\n",
       " (1607299200.0, 1607904000.0),\n",
       " (1607904000.0, 1608508800.0),\n",
       " (1608508800.0, 1609113600.0),\n",
       " (1609113600.0, 1609718400.0),\n",
       " (1609718400.0, 1610323200.0),\n",
       " (1610323200.0, 1610928000.0),\n",
       " (1610928000.0, 1611532800.0),\n",
       " (1611532800.0, 1612137600.0),\n",
       " (1612137600.0, 1612742400.0),\n",
       " (1612742400.0, 1613347200.0),\n",
       " (1613347200.0, 1613952000.0),\n",
       " (1613952000.0, 1614556800.0),\n",
       " (1614556800.0, 1615161600.0),\n",
       " (1615161600.0, 1615766400.0),\n",
       " (1615766400.0, 1616371200.0),\n",
       " (1616371200.0, 1616976000.0),\n",
       " (1616976000.0, 1617580800.0),\n",
       " (1617580800.0, 1618185600.0),\n",
       " (1618185600.0, 1618790400.0),\n",
       " (1618790400.0, 1619395200.0),\n",
       " (1619395200.0, 1620000000.0),\n",
       " (1620000000.0, 1620604800.0),\n",
       " (1620604800.0, 1621209600.0),\n",
       " (1621209600.0, 1621814400.0)]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weeks_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-3c25837388f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_weeks_utc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type tuple)"
     ]
    }
   ],
   "source": [
    "datetime.utcfromtimestamp(all_weeks_utc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_weeks = [weekFromDay(date) for date in surveyPeriods['A_I_start_date']]\n",
    "\n",
    "# Get first monday and last sunday from the A/I data collection periods\n",
    "firstDate,_ = weekFromDay(surveyPeriods['A_I_start_date'][0])\n",
    "_, lastDate = weekFromDay(surveyPeriods['A_I_start_date'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays = pd.date_range(firstDate, lastDate, freq='W-MON')\n",
    "leading_mondays = pd.date_range(nextMonday(firstDate), nextMonday(lastDate), freq='W-MON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-10-26', '2020-11-02', '2020-11-09', '2020-11-16',\n",
       "               '2020-11-23', '2020-11-30', '2020-12-07', '2020-12-14',\n",
       "               '2020-12-21', '2020-12-28', '2021-01-04', '2021-01-11',\n",
       "               '2021-01-18', '2021-01-25', '2021-02-01', '2021-02-08',\n",
       "               '2021-02-15', '2021-02-22', '2021-03-01', '2021-03-08',\n",
       "               '2021-03-15', '2021-03-22', '2021-03-29', '2021-04-05',\n",
       "               '2021-04-12', '2021-04-19', '2021-04-26', '2021-05-03',\n",
       "               '2021-05-10', '2021-05-17', '2021-05-24'],\n",
       "              dtype='datetime64[ns]', freq='W-MON')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leading_mondays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1603065600.0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_utc_timestamp(mondays[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcfromtimestamp(to_utc_timestamp(leading_mondays[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = weekFromDay(surveyPeriods['A_I_start_date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-19 00:00:00\n",
      "2020-10-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcfromtimestamp(a))\n",
    "print(datetime.utcfromtimestamp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1603065600.0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace(tzinfo = timezone.utc).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strptime() argument 1 must be str, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-2f38a6860a4c>\u001b[0m in \u001b[0;36mtoDatetime\u001b[0;34m(dateStr)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdateDT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdateStr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not tuple",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-6efcaaa3aac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweekFromDay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurveyPeriods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A_I_start_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoDatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtzinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimezone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-2f38a6860a4c>\u001b[0m in \u001b[0;36mtoDatetime\u001b[0;34m(dateStr)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdateDT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdateStr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%Y-%m-%dT%H:%M:%S.000Z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: strptime() argument 1 must be str, not tuple"
     ]
    }
   ],
   "source": [
    "start, end = weekFromDay(surveyPeriods['A_I_start_date'][0])\n",
    "bla = toDatetime(bla)\n",
    "bla = bla.replace(tzinfo = timezone.utc).timestamp()\n",
    "print(datetime.utcfromtimestamp(bla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 10, 19, 0, 0)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-06 22:59:59\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcfromtimestamp(bla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2021, 6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = toDatetime('2021-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = start_date.replace(tzinfo = timezone.utc).timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-204-0b744091dff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart_date\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcoffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'datetime.datetime' and 'NoneType'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-06 23:59:59\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(datetime.utcfromtimestamp(bla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 6, 6, 23, 59, 59)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1623621576.0\n",
      "2021-06-13 21:59:36\n",
      "1623625176\n",
      "2021-06-13 22:59:36\n"
     ]
    }
   ],
   "source": [
    "print(sub_recent['created'][0])\n",
    "print(datetime.utcfromtimestamp(float(sub_recent['created'][0])))\n",
    "\n",
    "\n",
    "print(sub_recent['created_utc'][0])\n",
    "print(datetime.utcfromtimestamp(float(sub_recent['created_utc'][0])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public        14657\n",
       "user           1151\n",
       "restricted      597\n",
       "Name: subreddit_type, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_recent['subreddit_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4657"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(sub_recent['subreddit']))\n",
    "# sub_recent['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12783"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(sub_recent['subreddit_subscribers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-06 23:00:10+00:00\n",
      "2021-06-13 22:59:36+00:00\n"
     ]
    }
   ],
   "source": [
    "# sub_recent['date'] = pd.to_datetime(sub_recent['created_utc'], utc=True, unit='s')\n",
    "print(min(sub_recent['date']))\n",
    "print(max(sub_recent['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_dist(submissions_data):\n",
    "    '''\n",
    "    is_created_from_ads_ui\n",
    "    is_crosspostable\n",
    "    is_meta\n",
    "    is_original_content\n",
    "    is_reddit_media_domain\n",
    "    is_robot_indexable\n",
    "    is_self\n",
    "    is_video\n",
    "    media_only\n",
    "    over_18\n",
    "    '''\n",
    "    \n",
    "    fields_dict = dict()\n",
    "    \n",
    "    l = len(submissions_data)\n",
    "    \n",
    "    fields_dict['is_ads'] = np.sum(submissions_data['is_created_from_ads_ui'])/l\n",
    "    fields_dict['is_crosspostable'] = np.sum(submissions_data['is_crosspostable'])/l\n",
    "    fields_dict['is_meta'] = np.sum(submissions_data['is_meta'])/l\n",
    "    fields_dict['is_original_content'] = np.sum(submissions_data['is_original_content'])/l\n",
    "    fields_dict['is_reddit_media_domain'] = np.sum(submissions_data['is_reddit_media_domain'])/l\n",
    "    fields_dict['is_robot_indexable'] = np.sum(submissions_data['is_robot_indexable'])/l\n",
    "    fields_dict['is_self'] = np.sum(submissions_data['is_self'])/l\n",
    "    fields_dict['is_video'] = np.sum(submissions_data['is_video'])/l\n",
    "    fields_dict['media_only'] = np.sum(submissions_data['media_only'])/l\n",
    "    fields_dict['over_18'] = np.sum(submissions_data['over_18'])/l\n",
    "    \n",
    "    for k,v in fields_dict.items():\n",
    "        print(k,\":\",round(v,3))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(f\"{round(fields_dict['ads'],3)}% created from ads\")\n",
    "#     print(f\"{round(fields_dict['crosspostable'],3)}% are crosspostable\")\n",
    "#     print(f\"{round(fields_dict['meta'],3)}% are meta\")\n",
    "#     print(f\"{round(fields_dict['original'],3)}% are OC\")\n",
    "#     print(f\"{round(fields_dict['media_domain'],3)}% are media_domain\")\n",
    "#     print(f\"{round(fields_dict['r_indexable'],3)}% are robot indexable\")\n",
    "#     print(f\"{round(fields_dict['self'],3)}% are self\")\n",
    "#     print(f\"{round(fields_dict['video'],3)}% are video\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     '''{}\\% of posts are created from ads\\n\n",
    "#     {}/% of posts are crosspostable\\n\n",
    "#     {}/% of posts are meta'''.\\\n",
    "#           format(round(p_ads,3), \n",
    "#                  round(p_crosspostable,3),\n",
    "#                  round(p_meta, 3))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ads : 0.003\n",
      "is_crosspostable : 0.936\n",
      "is_meta : 0.0\n",
      "is_original_content : 0.004\n",
      "is_reddit_media_domain : 0.027\n",
      "is_robot_indexable : 0.944\n",
      "is_self : 0.872\n",
      "is_video : 0.003\n"
     ]
    }
   ],
   "source": [
    "is_fields_dist(sub_recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ads 0.0032307223407497714\n",
      "crosspostable 0.935568424260896\n",
      "meta 0.0\n",
      "original 0.00365742151782993\n",
      "media_domain 0.027003962206644316\n",
      "r_indexable 0.943980493751905\n",
      "self 0.8715635476988723\n",
      "video 0.0028649801889667785\n"
     ]
    }
   ],
   "source": [
    "for k,v in bla.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all submissions with more than a certain upvote score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "api = PushshiftAPI()\n",
    "\n",
    "# Set up generator to make API request.\n",
    "api_request_generator = api.search_submissions(subreddit='news', score = \">2000\")\n",
    "\n",
    "# Make the request and collect results into a pd.DataFrame\n",
    "news_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "\n",
    "# Shape (n_results, n_features)\n",
    "news_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'allow_live_comments', 'author',\n",
       "       'author_flair_css_class', 'author_flair_richtext', 'author_flair_text',\n",
       "       'author_flair_type', 'author_fullname', 'author_patreon_flair',\n",
       "       'author_premium', 'awarders', 'can_mod_post', 'contest_mode',\n",
       "       'created_utc', 'domain', 'edited', 'full_link', 'gilded', 'gildings',\n",
       "       'id', 'is_crosspostable', 'is_meta', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_robot_indexable', 'is_self', 'is_video',\n",
       "       'link_flair_background_color', 'link_flair_richtext',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media_only',\n",
       "       'no_follow', 'num_comments', 'num_crossposts', 'over_18',\n",
       "       'parent_whitelist_status', 'permalink', 'pinned', 'pwls',\n",
       "       'retrieved_on', 'score', 'selftext', 'send_replies', 'spoiler',\n",
       "       'stickied', 'subreddit', 'subreddit_id', 'subreddit_subscribers',\n",
       "       'subreddit_type', 'thumbnail', 'title', 'total_awards_received',\n",
       "       'treatment_tags', 'upvote_ratio', 'url', 'whitelist_status', 'wls',\n",
       "       'created', 'link_flair_css_class', 'link_flair_text',\n",
       "       'removed_by_category', 'author_flair_background_color',\n",
       "       'author_flair_text_color', 'top_awarded_type', 'author_cakeday',\n",
       "       'link_flair_template_id', 'banned_by', 'steward_reports', 'updated_utc',\n",
       "       'og_description', 'og_title', 'rte_mode', 'author_id',\n",
       "       'previous_visits', 'brand_safe', 'post_hint', 'preview',\n",
       "       'suggested_sort', 'thumbnail_height', 'thumbnail_width',\n",
       "       'approved_at_utc', 'banned_at_utc', 'view_count', 'author_created_utc',\n",
       "       'media_embed', 'secure_media_embed', 'mod_reports', 'user_reports',\n",
       "       'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Available features\n",
    "news_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2019-07-24 03:28:46+00:00</td>\n",
       "      <td>My best friend called me and said \"An evil wiz...</td>\n",
       "      <td>12514</td>\n",
       "      <td>117</td>\n",
       "      <td>I drove all the way to his house just to find ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>2019-07-10 09:43:25+00:00</td>\n",
       "      <td>I went to the liquor store on my bicycle and b...</td>\n",
       "      <td>6395</td>\n",
       "      <td>93</td>\n",
       "      <td>\\n\\n...'cause I fell 7 times on the way home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2020-04-15 14:42:22+00:00</td>\n",
       "      <td>Husband doing crossword with his wife</td>\n",
       "      <td>2528</td>\n",
       "      <td>132</td>\n",
       "      <td>\\n\\nHusband: Emphatic no, five letters.\\n\\nWi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2019-04-18 20:13:24+00:00</td>\n",
       "      <td>The girl with no arms and legs laying by the pool</td>\n",
       "      <td>9047</td>\n",
       "      <td>238</td>\n",
       "      <td>There’s a girl with no arms and legs laying by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>2016-12-21 09:12:29+00:00</td>\n",
       "      <td>Break ups are the worst in China...</td>\n",
       "      <td>3047</td>\n",
       "      <td>180</td>\n",
       "      <td>You see her face everywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>2018-04-05 16:00:16+00:00</td>\n",
       "      <td>I asked my girlfriend to describe me in 5 words.</td>\n",
       "      <td>34538</td>\n",
       "      <td>537</td>\n",
       "      <td>She said I'm mature, I'm moral, I'm pure, I'm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>2017-02-18 22:10:34+00:00</td>\n",
       "      <td>Two blind pilots enter a plane</td>\n",
       "      <td>4247</td>\n",
       "      <td>100</td>\n",
       "      <td>They have sunglasses and white sticks. As the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>2018-05-19 15:06:42+00:00</td>\n",
       "      <td>Don't ever underestimate a Scottish police off...</td>\n",
       "      <td>5240</td>\n",
       "      <td>144</td>\n",
       "      <td>A London lawyer runs a stop sign and gets pull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2018-02-12 05:04:36+00:00</td>\n",
       "      <td>Afternoon Sex</td>\n",
       "      <td>36740</td>\n",
       "      <td>663</td>\n",
       "      <td>The only way to pull off a Sunday afternoon \"q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>2019-07-30 11:44:48+00:00</td>\n",
       "      <td>I once dated a girl who had a twin.</td>\n",
       "      <td>22951</td>\n",
       "      <td>356</td>\n",
       "      <td>People kept asking me how I could tell them ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>2018-06-18 06:06:45+00:00</td>\n",
       "      <td>I went on a date with a blonde woman last night.</td>\n",
       "      <td>20861</td>\n",
       "      <td>245</td>\n",
       "      <td>\"Do you have any kids?\" she asked.  \"Yes,\" I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>2015-04-17 10:38:20+00:00</td>\n",
       "      <td>A large woman, wearing a sleeveless sun dress,...</td>\n",
       "      <td>2140</td>\n",
       "      <td>51</td>\n",
       "      <td>She raised her right arm, revealing a huge, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>2018-04-16 23:37:34+00:00</td>\n",
       "      <td>What is a pirate's least favorite letter?</td>\n",
       "      <td>34812</td>\n",
       "      <td>561</td>\n",
       "      <td>Dear Sir/Ma'am,\\n\\nWe are cutting your interne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2018-04-21 14:20:39+00:00</td>\n",
       "      <td>It's the time of the French Revolution and the...</td>\n",
       "      <td>9609</td>\n",
       "      <td>248</td>\n",
       "      <td>Today they're leading a priest, a prostitute a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>2016-02-03 16:50:54+00:00</td>\n",
       "      <td>Why is Bernie Sanders challenging his 49 vs 50...</td>\n",
       "      <td>4260</td>\n",
       "      <td>673</td>\n",
       "      <td>I thought he didn't care about the 1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2020-04-12 00:45:03+00:00</td>\n",
       "      <td>HOW TO HAVE SEX WHILE ON LOCKDOWN WITH THE KID...</td>\n",
       "      <td>2571</td>\n",
       "      <td>327</td>\n",
       "      <td>The  only way to pull off a lockdown afternoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614</th>\n",
       "      <td>2017-05-28 10:58:47+00:00</td>\n",
       "      <td>KFC</td>\n",
       "      <td>7108</td>\n",
       "      <td>150</td>\n",
       "      <td>A man goes to see the pope.\\n\\n \"Your Holiness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2019-05-04 02:50:48+00:00</td>\n",
       "      <td>Today I saw a little boy wearing rags sitting ...</td>\n",
       "      <td>18939</td>\n",
       "      <td>259</td>\n",
       "      <td>I said, \"Awww, are you an orphan\"? He said, \"Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>2017-10-14 11:18:18+00:00</td>\n",
       "      <td>Three boys were talking after school...</td>\n",
       "      <td>2385</td>\n",
       "      <td>64</td>\n",
       "      <td>Three boys were talking after school while wai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>2016-12-10 02:02:03+00:00</td>\n",
       "      <td>I don't always tell dad jokes</td>\n",
       "      <td>18616</td>\n",
       "      <td>316</td>\n",
       "      <td>But when i do, he laughs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "747  2019-07-24 03:28:46+00:00   \n",
       "822  2019-07-10 09:43:25+00:00   \n",
       "161  2020-04-15 14:42:22+00:00   \n",
       "1312 2019-04-18 20:13:24+00:00   \n",
       "5600 2016-12-21 09:12:29+00:00   \n",
       "2864 2018-04-05 16:00:16+00:00   \n",
       "5254 2017-02-18 22:10:34+00:00   \n",
       "2569 2018-05-19 15:06:42+00:00   \n",
       "3232 2018-02-12 05:04:36+00:00   \n",
       "711  2019-07-30 11:44:48+00:00   \n",
       "2394 2018-06-18 06:06:45+00:00   \n",
       "7505 2015-04-17 10:38:20+00:00   \n",
       "2786 2018-04-16 23:37:34+00:00   \n",
       "2753 2018-04-21 14:20:39+00:00   \n",
       "6819 2016-02-03 16:50:54+00:00   \n",
       "185  2020-04-12 00:45:03+00:00   \n",
       "4614 2017-05-28 10:58:47+00:00   \n",
       "1205 2019-05-04 02:50:48+00:00   \n",
       "3830 2017-10-14 11:18:18+00:00   \n",
       "5649 2016-12-10 02:02:03+00:00   \n",
       "\n",
       "                                                  title  score  num_comments  \\\n",
       "747   My best friend called me and said \"An evil wiz...  12514           117   \n",
       "822   I went to the liquor store on my bicycle and b...   6395            93   \n",
       "161               Husband doing crossword with his wife   2528           132   \n",
       "1312  The girl with no arms and legs laying by the pool   9047           238   \n",
       "5600                Break ups are the worst in China...   3047           180   \n",
       "2864   I asked my girlfriend to describe me in 5 words.  34538           537   \n",
       "5254                     Two blind pilots enter a plane   4247           100   \n",
       "2569  Don't ever underestimate a Scottish police off...   5240           144   \n",
       "3232                                      Afternoon Sex  36740           663   \n",
       "711                 I once dated a girl who had a twin.  22951           356   \n",
       "2394   I went on a date with a blonde woman last night.  20861           245   \n",
       "7505  A large woman, wearing a sleeveless sun dress,...   2140            51   \n",
       "2786          What is a pirate's least favorite letter?  34812           561   \n",
       "2753  It's the time of the French Revolution and the...   9609           248   \n",
       "6819  Why is Bernie Sanders challenging his 49 vs 50...   4260           673   \n",
       "185   HOW TO HAVE SEX WHILE ON LOCKDOWN WITH THE KID...   2571           327   \n",
       "4614                                                KFC   7108           150   \n",
       "1205  Today I saw a little boy wearing rags sitting ...  18939           259   \n",
       "3830            Three boys were talking after school...   2385            64   \n",
       "5649                      I don't always tell dad jokes  18616           316   \n",
       "\n",
       "                                               selftext  \n",
       "747   I drove all the way to his house just to find ...  \n",
       "822     \\n\\n...'cause I fell 7 times on the way home...  \n",
       "161    \\n\\nHusband: Emphatic no, five letters.\\n\\nWi...  \n",
       "1312  There’s a girl with no arms and legs laying by...  \n",
       "5600                       You see her face everywhere.  \n",
       "2864  She said I'm mature, I'm moral, I'm pure, I'm ...  \n",
       "5254  They have sunglasses and white sticks. As the ...  \n",
       "2569  A London lawyer runs a stop sign and gets pull...  \n",
       "3232  The only way to pull off a Sunday afternoon \"q...  \n",
       "711   People kept asking me how I could tell them ap...  \n",
       "2394  \"Do you have any kids?\" she asked.  \"Yes,\" I r...  \n",
       "7505  She raised her right arm, revealing a huge, ha...  \n",
       "2786  Dear Sir/Ma'am,\\n\\nWe are cutting your interne...  \n",
       "2753  Today they're leading a priest, a prostitute a...  \n",
       "6819              I thought he didn't care about the 1%  \n",
       "185   The  only way to pull off a lockdown afternoon...  \n",
       "4614  A man goes to see the pope.\\n\\n \"Your Holiness...  \n",
       "1205  I said, \"Awww, are you an orphan\"? He said, \"Y...  \n",
       "3830  Three boys were talking after school while wai...  \n",
       "5649                          But when i do, he laughs   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform to datetime\n",
    "news_submissions['date'] = pd.to_datetime(jokes_submissions['created_utc'], utc = True, unit = 's')\n",
    "news_submissions[['date','title', 'score', 'num_comments', 'selftext']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting submission based on search keyword\n",
    "\n",
    "Searching comments is done in the same way, but using api.search_comments instead of api.search_submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4645, 102)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up generator to make API request.\n",
    "api_request_generator = api.search_submissions(q='(jobs | employment)', score = '>2000')\n",
    "\n",
    "q_jobs_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "\n",
    "q_jobs_submissions['date'] = pd.to_datetime(q_jobs_submissions['created_utc'], utc=True, unit='s')\n",
    "\n",
    "q_jobs_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2020-07-21 18:38:33+00:00</td>\n",
       "      <td>Aita for calling out my sister after she shame...</td>\n",
       "      <td>12490</td>\n",
       "      <td>1036</td>\n",
       "      <td>I’m 28 my sister is 26. She got married three ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>2018-03-05 16:21:16+00:00</td>\n",
       "      <td>TIL Before he was a famous musician Johnny Cas...</td>\n",
       "      <td>32066</td>\n",
       "      <td>499</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>2016-10-09 18:06:11+00:00</td>\n",
       "      <td>My boyfriend and I started a business out of h...</td>\n",
       "      <td>3612</td>\n",
       "      <td>2867</td>\n",
       "      <td>Hi Reddit! I’m Monique. Two years ago I was wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>2016-07-24 12:55:42+00:00</td>\n",
       "      <td>EMSK the most popular resumes are either chron...</td>\n",
       "      <td>2039</td>\n",
       "      <td>54</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2017-01-26 12:45:34+00:00</td>\n",
       "      <td>Keystone pipeline will create just 35 permanen...</td>\n",
       "      <td>31452</td>\n",
       "      <td>3040</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2019-08-15 07:08:55+00:00</td>\n",
       "      <td>Video Game Developer Insight on EA's Relations...</td>\n",
       "      <td>2581</td>\n",
       "      <td>460</td>\n",
       "      <td>I've been a video game developer for near thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>2018-03-23 15:14:04+00:00</td>\n",
       "      <td>I work as a companion to a man who has Down sy...</td>\n",
       "      <td>3045</td>\n",
       "      <td>251</td>\n",
       "      <td>His Individual Support Plan allows for no alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2019-07-19 10:47:41+00:00</td>\n",
       "      <td>Fine! But you're stealing their jobs!</td>\n",
       "      <td>3068</td>\n",
       "      <td>163</td>\n",
       "      <td>I love Target. I'm also a stress eater who hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>2016-11-30 00:42:18+00:00</td>\n",
       "      <td>You are only a Temp!</td>\n",
       "      <td>3459</td>\n",
       "      <td>253</td>\n",
       "      <td>So in my time out of tech support from the lig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>2016-07-26 04:35:07+00:00</td>\n",
       "      <td>Ken M On Six-Figure Jobs</td>\n",
       "      <td>3944</td>\n",
       "      <td>163</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>2015-10-20 00:41:48+00:00</td>\n",
       "      <td>TIL that in Saudi Arabia, all women, regardles...</td>\n",
       "      <td>2401</td>\n",
       "      <td>367</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2019-07-15 12:41:57+00:00</td>\n",
       "      <td>Watching a speech by Steve Jobs about marketin...</td>\n",
       "      <td>4925</td>\n",
       "      <td>757</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2019-08-28 13:18:30+00:00</td>\n",
       "      <td>\"Just prioritize and don't feel guilty,\" says ...</td>\n",
       "      <td>3695</td>\n",
       "      <td>309</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>2016-10-08 20:09:53+00:00</td>\n",
       "      <td>What's good for the goose...</td>\n",
       "      <td>2656</td>\n",
       "      <td>89</td>\n",
       "      <td>In the early '90s, I worked as a pressman for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4352</th>\n",
       "      <td>2014-07-09 21:49:19+00:00</td>\n",
       "      <td>TIL: \"Government once even claimed that Hooter...</td>\n",
       "      <td>2676</td>\n",
       "      <td>568</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2019-09-25 02:24:33+00:00</td>\n",
       "      <td>Small breasts are infinitely better than huge ...</td>\n",
       "      <td>15320</td>\n",
       "      <td>1632</td>\n",
       "      <td>Fake breasts look like they're...fake. They ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2019-11-03 06:40:58+00:00</td>\n",
       "      <td>This sub infuriates me</td>\n",
       "      <td>4150</td>\n",
       "      <td>1211</td>\n",
       "      <td>Before I get loads of comments telling me \"You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>2015-10-23 15:28:30+00:00</td>\n",
       "      <td>LPT: If you start a new job and think you may ...</td>\n",
       "      <td>3449</td>\n",
       "      <td>1308</td>\n",
       "      <td>I've done this for the past three jobs and I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3372</th>\n",
       "      <td>2016-12-12 05:01:43+00:00</td>\n",
       "      <td>Make Aatrox Great Again!</td>\n",
       "      <td>8064</td>\n",
       "      <td>594</td>\n",
       "      <td>Aatrox is in serious trouble. He doesn’t have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051</th>\n",
       "      <td>2015-08-20 12:04:35+00:00</td>\n",
       "      <td>I have a feeling that Bruce Wayne would be bet...</td>\n",
       "      <td>3243</td>\n",
       "      <td>322</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "115  2020-07-21 18:38:33+00:00   \n",
       "2041 2018-03-05 16:21:16+00:00   \n",
       "3571 2016-10-09 18:06:11+00:00   \n",
       "3687 2016-07-24 12:55:42+00:00   \n",
       "3202 2017-01-26 12:45:34+00:00   \n",
       "577  2019-08-15 07:08:55+00:00   \n",
       "1973 2018-03-23 15:14:04+00:00   \n",
       "687  2019-07-19 10:47:41+00:00   \n",
       "3446 2016-11-30 00:42:18+00:00   \n",
       "3683 2016-07-26 04:35:07+00:00   \n",
       "3999 2015-10-20 00:41:48+00:00   \n",
       "706  2019-07-15 12:41:57+00:00   \n",
       "513  2019-08-28 13:18:30+00:00   \n",
       "3573 2016-10-08 20:09:53+00:00   \n",
       "4352 2014-07-09 21:49:19+00:00   \n",
       "388  2019-09-25 02:24:33+00:00   \n",
       "226  2019-11-03 06:40:58+00:00   \n",
       "3995 2015-10-23 15:28:30+00:00   \n",
       "3372 2016-12-12 05:01:43+00:00   \n",
       "4051 2015-08-20 12:04:35+00:00   \n",
       "\n",
       "                                                  title  score  num_comments  \\\n",
       "115   Aita for calling out my sister after she shame...  12490          1036   \n",
       "2041  TIL Before he was a famous musician Johnny Cas...  32066           499   \n",
       "3571  My boyfriend and I started a business out of h...   3612          2867   \n",
       "3687  EMSK the most popular resumes are either chron...   2039            54   \n",
       "3202  Keystone pipeline will create just 35 permanen...  31452          3040   \n",
       "577   Video Game Developer Insight on EA's Relations...   2581           460   \n",
       "1973  I work as a companion to a man who has Down sy...   3045           251   \n",
       "687               Fine! But you're stealing their jobs!   3068           163   \n",
       "3446                               You are only a Temp!   3459           253   \n",
       "3683                           Ken M On Six-Figure Jobs   3944           163   \n",
       "3999  TIL that in Saudi Arabia, all women, regardles...   2401           367   \n",
       "706   Watching a speech by Steve Jobs about marketin...   4925           757   \n",
       "513   \"Just prioritize and don't feel guilty,\" says ...   3695           309   \n",
       "3573                       What's good for the goose...   2656            89   \n",
       "4352  TIL: \"Government once even claimed that Hooter...   2676           568   \n",
       "388   Small breasts are infinitely better than huge ...  15320          1632   \n",
       "226                              This sub infuriates me   4150          1211   \n",
       "3995  LPT: If you start a new job and think you may ...   3449          1308   \n",
       "3372                           Make Aatrox Great Again!   8064           594   \n",
       "4051  I have a feeling that Bruce Wayne would be bet...   3243           322   \n",
       "\n",
       "                                               selftext  \n",
       "115   I’m 28 my sister is 26. She got married three ...  \n",
       "2041                                                     \n",
       "3571  Hi Reddit! I’m Monique. Two years ago I was wo...  \n",
       "3687                                          [deleted]  \n",
       "3202                                                     \n",
       "577   I've been a video game developer for near thre...  \n",
       "1973  His Individual Support Plan allows for no alon...  \n",
       "687   I love Target. I'm also a stress eater who hap...  \n",
       "3446  So in my time out of tech support from the lig...  \n",
       "3683                                                     \n",
       "3999                                                     \n",
       "706                                                      \n",
       "513                                                      \n",
       "3573  In the early '90s, I worked as a pressman for ...  \n",
       "4352                                                     \n",
       "388   Fake breasts look like they're...fake. They ra...  \n",
       "226   Before I get loads of comments telling me \"You...  \n",
       "3995  I've done this for the past three jobs and I'm...  \n",
       "3372  Aatrox is in serious trouble. He doesn’t have ...  \n",
       "4051                                                     "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_submissions[['date','title', 'score', 'num_comments', 'selftext']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-06-14 02:29:15+0000', tz='UTC')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(q_jobs_submissions['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect submissions/comments within a certain period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6205, 99)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = int(datetime(2020, 10, 23).timestamp())\n",
    "end_time = int(datetime(2020, 10, 26).timestamp())\n",
    "\n",
    "api_request_generator = api.search_submissions(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time)\n",
    "\n",
    "q_jobs_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 71)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = int(datetime(2020, 10, 23).timestamp())\n",
    "end_time = int(datetime(2020, 10, 26).timestamp())\n",
    "\n",
    "api_request_generator2 = api.search_submissions(q='(jobs OR employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time)\n",
    "\n",
    "q_jobs_submissions2 = pd.DataFrame([submission.d_ for submission in api_request_generator2])\n",
    "q_jobs_submissions2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>2020-10-25 03:22:31+00:00</td>\n",
       "      <td>I’m addicted to caffeine pills</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>I probably take 1000mg-1400mg is caffeine a da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>2020-10-23 21:50:56+00:00</td>\n",
       "      <td>Question about gaps after a foundation program...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Hello, I wanna ask about a gap in trade.\\n\\nI'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5805</th>\n",
       "      <td>2020-10-23 03:14:45+00:00</td>\n",
       "      <td>HOW THIS WORKS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n* Website of the course: https://LinuxUpskil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>2020-10-23 10:29:21+00:00</td>\n",
       "      <td>Revamp your problems by the help of real black...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\n[  ](https://preview.redd.it/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>2020-10-23 03:54:07+00:00</td>\n",
       "      <td>Scrapping together a network</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>So I got a bunch of gear that our shop has acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2020-10-24 16:20:41+00:00</td>\n",
       "      <td>Our new home. ♥️ It’s about 400 years old. We ...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>2020-10-24 22:44:32+00:00</td>\n",
       "      <td>Can you get the full maternity EI amount over ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Let's say maternity EI pays you 500 a week for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>2020-10-25 12:58:31+00:00</td>\n",
       "      <td>Amateur &amp;amp; POV doggy, anal, blow jobs, cum ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>2020-10-23 12:37:24+00:00</td>\n",
       "      <td>What exactly does the 'Check Access' button in...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hello all\\n\\nWe are having trouble with device...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>2020-10-24 00:26:20+00:00</td>\n",
       "      <td>The job market seriously stinks</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>I enlisted in the Air Force at the start of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>2020-10-24 23:02:38+00:00</td>\n",
       "      <td>(M4F) Feminine media student's first encounter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Having spent the last 3 years in College study...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>2020-10-23 00:03:41+00:00</td>\n",
       "      <td>@AFP: \"People are starting new businesses beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2020-10-24 23:44:10+00:00</td>\n",
       "      <td>WhiteHouse: For decades, American manufacturin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>2020-10-24 08:58:39+00:00</td>\n",
       "      <td>Freshers job prospects for Engineering Management</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>I'm planning on pursing a master's degree in E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>2020-10-23 06:24:57+00:00</td>\n",
       "      <td>u/AltAccount 1-_-1 Making a Smarty 19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Yaaawwwn. He always hated the day times. So bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>2020-10-23 03:29:47+00:00</td>\n",
       "      <td>👩‍❤️‍👨COUPLES content👩‍❤️‍👨 ⭐️Top 10% ⭐️ ❌NO P...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>2020-10-24 17:07:47+00:00</td>\n",
       "      <td>How to get a Tax Identification Number (TIN) f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2020-10-25 12:07:37+00:00</td>\n",
       "      <td>How do you invoice your clients?</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>If you use an invoice, do you seperate everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>2020-10-24 00:17:22+00:00</td>\n",
       "      <td>[M4F] Your new job</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you have just turned 18, and got your first jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4549</th>\n",
       "      <td>2020-10-23 17:34:14+00:00</td>\n",
       "      <td>you can hire jobs at part time get info hourly...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[https://www.petconearme1.com/petco-jobs-near-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "1630 2020-10-25 03:22:31+00:00   \n",
       "4054 2020-10-23 21:50:56+00:00   \n",
       "5805 2020-10-23 03:14:45+00:00   \n",
       "5259 2020-10-23 10:29:21+00:00   \n",
       "5724 2020-10-23 03:54:07+00:00   \n",
       "2594 2020-10-24 16:20:41+00:00   \n",
       "1979 2020-10-24 22:44:32+00:00   \n",
       "1034 2020-10-25 12:58:31+00:00   \n",
       "5072 2020-10-23 12:37:24+00:00   \n",
       "3810 2020-10-24 00:26:20+00:00   \n",
       "1958 2020-10-24 23:02:38+00:00   \n",
       "6118 2020-10-23 00:03:41+00:00   \n",
       "1902 2020-10-24 23:44:10+00:00   \n",
       "3185 2020-10-24 08:58:39+00:00   \n",
       "5516 2020-10-23 06:24:57+00:00   \n",
       "5765 2020-10-23 03:29:47+00:00   \n",
       "2523 2020-10-24 17:07:47+00:00   \n",
       "1094 2020-10-25 12:07:37+00:00   \n",
       "3822 2020-10-24 00:17:22+00:00   \n",
       "4549 2020-10-23 17:34:14+00:00   \n",
       "\n",
       "                                                  title  score  num_comments  \\\n",
       "1630                     I’m addicted to caffeine pills      1            16   \n",
       "4054  Question about gaps after a foundation program...      1             4   \n",
       "5805                                  HOW THIS WORKS...      1             0   \n",
       "5259  Revamp your problems by the help of real black...      1             0   \n",
       "5724                       Scrapping together a network      1             5   \n",
       "2594  Our new home. ♥️ It’s about 400 years old. We ...      1            34   \n",
       "1979  Can you get the full maternity EI amount over ...      1             8   \n",
       "1034  Amateur &amp; POV doggy, anal, blow jobs, cum ...      1             2   \n",
       "5072  What exactly does the 'Check Access' button in...      1             3   \n",
       "3810                    The job market seriously stinks      1             8   \n",
       "1958  (M4F) Feminine media student's first encounter...      1             0   \n",
       "6118  @AFP: \"People are starting new businesses beca...      1             0   \n",
       "1902  WhiteHouse: For decades, American manufacturin...      1             0   \n",
       "3185  Freshers job prospects for Engineering Management      1            10   \n",
       "5516              u/AltAccount 1-_-1 Making a Smarty 19      1             2   \n",
       "5765  👩‍❤️‍👨COUPLES content👩‍❤️‍👨 ⭐️Top 10% ⭐️ ❌NO P...      1             4   \n",
       "2523  How to get a Tax Identification Number (TIN) f...      1             0   \n",
       "1094                   How do you invoice your clients?      1            17   \n",
       "3822                                 [M4F] Your new job      1             0   \n",
       "4549  you can hire jobs at part time get info hourly...      1             1   \n",
       "\n",
       "                                               selftext  \n",
       "1630  I probably take 1000mg-1400mg is caffeine a da...  \n",
       "4054  Hello, I wanna ask about a gap in trade.\\n\\nI'...  \n",
       "5805  \\n* Website of the course: https://LinuxUpskil...  \n",
       "5259  &amp;#x200B;\\n\\n[  ](https://preview.redd.it/t...  \n",
       "5724  So I got a bunch of gear that our shop has acc...  \n",
       "2594                                                     \n",
       "1979  Let's say maternity EI pays you 500 a week for...  \n",
       "1034                                                     \n",
       "5072  Hello all\\n\\nWe are having trouble with device...  \n",
       "3810  I enlisted in the Air Force at the start of th...  \n",
       "1958  Having spent the last 3 years in College study...  \n",
       "6118                                                     \n",
       "1902                                                     \n",
       "3185  I'm planning on pursing a master's degree in E...  \n",
       "5516  Yaaawwwn. He always hated the day times. So bo...  \n",
       "5765                                                     \n",
       "2523                                                     \n",
       "1094  If you use an invoice, do you seperate everyth...  \n",
       "3822  you have just turned 18, and got your first jo...  \n",
       "4549  [https://www.petconearme1.com/petco-jobs-near-...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_submissions['date'] = pd.to_datetime(q_jobs_submissions['created_utc'], utc=True, unit='s')\n",
    "q_jobs_submissions[['date','title', 'score', 'num_comments', 'selftext']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 611\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-026950f2ef79>\", line 1, in <module>\n",
      "    q_jobs_submissions['selftext', 'subreddit'][5805]\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/frame.py\", line 3024, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3082, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-026950f2ef79>\", line 1, in <module>\n",
      "    q_jobs_submissions['selftext', 'subreddit'][5805]\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/frame.py\", line 3024, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3082, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n",
      "    return self._engine.get_loc(casted_key)\n",
      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-026950f2ef79>\", line 1, in <module>\n",
      "    q_jobs_submissions['selftext', 'subreddit'][5805]\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/frame.py\", line 3024, in __getitem__\n",
      "    indexer = self.columns.get_loc(key)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 3082, in get_loc\n",
      "    raise KeyError(key) from err\n",
      "KeyError: ('selftext', 'subreddit')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3170, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3380, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "q_jobs_submissions['selftext', 'subreddit'][5805]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-10-24 18:22:02+00:00</td>\n",
       "      <td>Do I have to list ALL past employment on appli...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>I am 29 and applying for law school for the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-10-25 01:52:09+00:00</td>\n",
       "      <td>Why are so many people relying on a stimulus?</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>This is not meant to be demeaning or insulting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2020-10-23 19:46:58+00:00</td>\n",
       "      <td>I never thought I could hate someone so much.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>My belief that being friends with an ex is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-10-23 23:36:18+00:00</td>\n",
       "      <td>35 [M4F] I want to turn you into white trash</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Have you ever wanted to just \"let go\"?  To sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-10-25 08:08:50+00:00</td>\n",
       "      <td>I'm a public policy analyst that has dedicated...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Hey peeps,\\n\\nMy name is Tudor! By trade, I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-25 20:25:33+00:00</td>\n",
       "      <td>Was super excited about finally getting a job,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I don’t even know how to start with this. Apol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-10-25 15:59:03+00:00</td>\n",
       "      <td>Hi there. I'm thinking of applying to the Robe...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hi there. I'm thinking of applying to the Robe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2020-10-23 21:55:57+00:00</td>\n",
       "      <td>Moving to Winnipeg from Edmonton, what is the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>I currently work for the Government of Alberta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2020-10-23 20:18:48+00:00</td>\n",
       "      <td>prop 22</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Disclaimer: I'm sorry if this does not belong ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2020-10-23 16:45:32+00:00</td>\n",
       "      <td>[HIRING] Research Data Analyst at University o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>University of California, Riverside is looking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-10-25 12:13:24+00:00</td>\n",
       "      <td>The core of the problem.</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>Why traditional gender roles exist(ed) ? there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-10-25 07:42:22+00:00</td>\n",
       "      <td>I'm a public policy analyst that has dedicated...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>Hey peeps,  \\n\\n\\nThis might be a little bit o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2020-10-23 00:28:53+00:00</td>\n",
       "      <td>Do Latina Women have an advantage when it come...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>Before I start, I just want to make it clear.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-25 19:14:39+00:00</td>\n",
       "      <td>Quit the job I had lined up because the compan...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I don’t even know how to start with this. I’ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-10-24 18:25:50+00:00</td>\n",
       "      <td>2/2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tomorrow night on Bee Larry King,     we'll h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-10-24 10:24:09+00:00</td>\n",
       "      <td>I lied on my resume, do I even try saving the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>So yeah, I messed up bad. I don't need scolded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2020-10-23 02:13:58+00:00</td>\n",
       "      <td>Short on cash for first and last month’s rent?...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The city offers an interest-free loan of up to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-25 22:44:00+00:00</td>\n",
       "      <td>Employment Section Help</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This may be a stupid question, but I'm stressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-10-24 21:27:27+00:00</td>\n",
       "      <td>I truly believe that robots are going to take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>But not in the way you think. Everyone has thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-10-24 10:54:25+00:00</td>\n",
       "      <td>Hello all. Well it has just passed a week</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>We were in that horrible transitional phase of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "27 2020-10-24 18:22:02+00:00   \n",
       "21 2020-10-25 01:52:09+00:00   \n",
       "45 2020-10-23 19:46:58+00:00   \n",
       "41 2020-10-23 23:36:18+00:00   \n",
       "16 2020-10-25 08:08:50+00:00   \n",
       "4  2020-10-25 20:25:33+00:00   \n",
       "10 2020-10-25 15:59:03+00:00   \n",
       "43 2020-10-23 21:55:57+00:00   \n",
       "44 2020-10-23 20:18:48+00:00   \n",
       "48 2020-10-23 16:45:32+00:00   \n",
       "13 2020-10-25 12:13:24+00:00   \n",
       "17 2020-10-25 07:42:22+00:00   \n",
       "62 2020-10-23 00:28:53+00:00   \n",
       "5  2020-10-25 19:14:39+00:00   \n",
       "25 2020-10-24 18:25:50+00:00   \n",
       "35 2020-10-24 10:24:09+00:00   \n",
       "60 2020-10-23 02:13:58+00:00   \n",
       "1  2020-10-25 22:44:00+00:00   \n",
       "22 2020-10-24 21:27:27+00:00   \n",
       "34 2020-10-24 10:54:25+00:00   \n",
       "\n",
       "                                                title  score  num_comments  \\\n",
       "27  Do I have to list ALL past employment on appli...      1            12   \n",
       "21      Why are so many people relying on a stimulus?      1           202   \n",
       "45      I never thought I could hate someone so much.      1             2   \n",
       "41       35 [M4F] I want to turn you into white trash      1             0   \n",
       "16  I'm a public policy analyst that has dedicated...      1             9   \n",
       "4   Was super excited about finally getting a job,...      1             0   \n",
       "10  Hi there. I'm thinking of applying to the Robe...      1             3   \n",
       "43  Moving to Winnipeg from Edmonton, what is the ...      1            21   \n",
       "44                                            prop 22      1            13   \n",
       "48  [HIRING] Research Data Analyst at University o...      1             0   \n",
       "13                           The core of the problem.      1            42   \n",
       "17  I'm a public policy analyst that has dedicated...      1            12   \n",
       "62  Do Latina Women have an advantage when it come...      1            31   \n",
       "5   Quit the job I had lined up because the compan...      1             5   \n",
       "25                                                2/2      1             0   \n",
       "35  I lied on my resume, do I even try saving the ...      1             3   \n",
       "60  Short on cash for first and last month’s rent?...      1             5   \n",
       "1                             Employment Section Help      1             1   \n",
       "22  I truly believe that robots are going to take ...      1            15   \n",
       "34          Hello all. Well it has just passed a week      1             1   \n",
       "\n",
       "                                             selftext  \n",
       "27  I am 29 and applying for law school for the fi...  \n",
       "21  This is not meant to be demeaning or insulting...  \n",
       "45  My belief that being friends with an ex is ver...  \n",
       "41  Have you ever wanted to just \"let go\"?  To sto...  \n",
       "16   Hey peeps,\\n\\nMy name is Tudor! By trade, I a...  \n",
       "4   I don’t even know how to start with this. Apol...  \n",
       "10  Hi there. I'm thinking of applying to the Robe...  \n",
       "43  I currently work for the Government of Alberta...  \n",
       "44  Disclaimer: I'm sorry if this does not belong ...  \n",
       "48  University of California, Riverside is looking...  \n",
       "13  Why traditional gender roles exist(ed) ? there...  \n",
       "17  Hey peeps,  \\n\\n\\nThis might be a little bit o...  \n",
       "62  Before I start, I just want to make it clear.....  \n",
       "5   I don’t even know how to start with this. I’ve...  \n",
       "25   Tomorrow night on Bee Larry King,     we'll h...  \n",
       "35  So yeah, I messed up bad. I don't need scolded...  \n",
       "60  The city offers an interest-free loan of up to...  \n",
       "1   This may be a stupid question, but I'm stressi...  \n",
       "22  But not in the way you think. Everyone has thi...  \n",
       "34  We were in that horrible transitional phase of...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_submissions2['date'] = pd.to_datetime(q_jobs_submissions2['created_utc'], utc=True, unit='s')\n",
    "q_jobs_submissions2[['date','title', 'score', 'num_comments', 'selftext']].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My belief that being friends with an ex is very rare, and even in those rarities there are many attempting to be friends and haven’t quite realized the ship they’re trying to salvage is already sunk. \\n\\nI happen to be in one of these situations. At this point the only options is ghosting, as bad as it sounds, it is the only healthy choice. I’m not the greatest person in the world I may even share some of the Narc traits my ex has, it could be one of the biggest reasons I feel I hate her. But it’s not the only reason by a long shot.\\n\\nShe’s reached out and I have reached out when I know I shouldn’t have. Anytime we connect now it’s usually me who starts an argument because shes doing and saying the same things that added to our inviability. She starts complaining about someone making her feel a certain way, there’s something for her to complain about constantly, and she still talks about her ex, comparing me to him, and I’m sitting there like wait wtf I don’t have to listen to any of the shit anymore, none of it. What makes me hate her aren’t these things, it’s how she justifies things. “I can’t let things go” “she’s not that person anymore” “she has depression” “her mom could die any day” “she’s feeling suicidal” “I should grow up, and be attentive and cut her slack because she has mental issues” “I’m the one not allowing us to be friends”. \\n\\nBottom line we’re both screwed up in many similar ways, what I don’t do though is hold other people accountable for things that go wrong or that I caused. A friend told her to leave and she wants to call me to vent about it, but I know already it’s because she wore out her welcome, she has this odd sense of entitlement, I myself can’t stand to be in her presence for too long, I’ve had to ask her to leave myself. She leaves the house late misses the bus, it’s because the busses never run on time. She gets fired, because no one at the job liked her and they all wanted her gone. When we first met, she told me about her first apartment and that she got evicted, but she has no idea how it happened, she did everything she was supposed to do. The most resent apartment the same thing happened this time I was living with her, before we moved in I quit my job. She continued to work, I kept the place clean I cooked every night, she came home everyday and chewed me out. It took me only a month to find employment, which almost immediately after I did she quit her job, I worked and came home every day to listen to her complain about how hard her day was, she showed me constantly, applications she’d put into jobs she’d never get she doesn’t have a diploma/ged this went on for four months during and after that time she complained about how my efforts were minuscule compared to hers. She’d say off the wall shit to me pride her self on being blunt and straightforward then tell me I owe her an apology because of how what I said made her feel. We lived together broken up for a while and she attempted therapy  after always saying “they can’t help me, they don’t know what they’re talking about”. She came home one day and says to me “can you believe this woman tried to tell me I have Borderline Personality Disorder? Waste of time I’m not going back”. : |  I’ve never met a more pretentious person in my life. I miss the fleeting fun we still sometimes have, but with out doubt over all I hate this woman I absolutely hate her, and I wish that I didn’t still have any love for her. \\n\\nShout out to anyone who’s been diagnosed or diagnosed themselves with any mental issue, and use it as an excuse to be a shitty ass piece of shit human being, we’re all fucking depressed we live in the US most of us have jobs we hate that we spend more time earning peanuts at than the reasons we’re working. I myself have been diagnosed but it’s not a fucking weapon, and it doesn’t just pop up in conversations, only me and one other person knows. You may not have created your issues, but unfortunately they are yours to deal with now, no one else’s, support is necessary but it’s pretty easy to abuse. Men and women mostly women guys tend to suffer in silence, it can be a wonderful thing to find a partner who’s your knight in shining armor, they’re stable, and they also have the capacity to fully take on all your issues, but it isn’t realistic.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_submissions2['selftext'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35706, 39)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = int(datetime(2020, 10, 23).timestamp())\n",
    "end_time = int(datetime(2020, 10, 26).timestamp())\n",
    "\n",
    "api_request_generator = api.search_comments(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time)\n",
    "\n",
    "q_jobs_comments = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_comments['date'] = pd.to_datetime(q_jobs_comments['created_utc'], utc=True, unit='s')\n",
    "q_jobs_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'associated_award', 'author',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_richtext', 'author_flair_template_id',\n",
       "       'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
       "       'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
       "       'body', 'collapsed_because_crowd_control', 'comment_type',\n",
       "       'created_utc', 'gildings', 'id', 'is_submitter', 'link_id', 'locked',\n",
       "       'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score',\n",
       "       'send_replies', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'top_awarded_type', 'total_awards_received', 'treatment_tags',\n",
       "       'created', 'distinguished', 'edited', 'author_cakeday', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 612\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-cd530e1fd048>\", line 1, in <module>\n",
      "    q_jobs_comments[['date', 'score', 'body', 'parent_id']].sample(20)\n",
      "NameError: name 'q_jobs_comments' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-cd530e1fd048>\", line 1, in <module>\n",
      "    q_jobs_comments[['date', 'score', 'body', 'parent_id']].sample(20)\n",
      "NameError: name 'q_jobs_comments' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-cd530e1fd048>\", line 1, in <module>\n",
      "    q_jobs_comments[['date', 'score', 'body', 'parent_id']].sample(20)\n",
      "NameError: name 'q_jobs_comments' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2944, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3170, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3380, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2064, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/munchausend/.local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "q_jobs_comments[['date', 'score', 'body', 'parent_id']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/Users/munchausend/opt/anaconda3/envs/redditScrapper/lib/python3.7/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6205, 6)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_request_generator = api.search_submissions(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time, \n",
    "                                              filter=['url','author', 'title', 'subreddit'],\n",
    "                                              limit = 10000)\n",
    "\n",
    "q_jobs_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_jobs_submissions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files that are returned can be filtered by adding ```filter = ['field1','field2']``` in the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission & comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6205, 99)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = int(datetime(2020, 10, 23).timestamp())\n",
    "end_time = int(datetime(2020, 10, 26).timestamp())\n",
    "\n",
    "api_request_generator = api.search_submissions(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time)\n",
    "\n",
    "q_jobs_submissions = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 66)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_request_generator = api.search_submissions(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time, \n",
    "                                              score = \">1\")\n",
    "\n",
    "q_jobs_submissions2 = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_submissions2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_request_generator = api.search_submissions(q='(employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time, \n",
    "                                              score = \">1\")\n",
    "\n",
    "q_jobs_submissions2 = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_submissions2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35706, 40)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_request_generator = api.search_comments(q='(jobs | employment)',\n",
    "                                              after = start_time,\n",
    "                                              before = end_time)\n",
    "\n",
    "q_jobs_comments = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_comments['date'] = pd.to_datetime(q_jobs_comments['created_utc'], utc=True, unit='s')\n",
    "q_jobs_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['all_awardings', 'associated_award', 'author',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_richtext', 'author_flair_template_id',\n",
       "       'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
       "       'author_fullname', 'author_patreon_flair', 'author_premium', 'awarders',\n",
       "       'body', 'collapsed_because_crowd_control', 'comment_type',\n",
       "       'created_utc', 'gildings', 'id', 'is_submitter', 'link_id', 'locked',\n",
       "       'no_follow', 'parent_id', 'permalink', 'retrieved_on', 'score',\n",
       "       'send_replies', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'top_awarded_type', 'total_awards_received', 'treatment_tags',\n",
       "       'created', 'distinguished', 'edited', 'author_cakeday', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_comments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ids = q_jobs_submissions['id']\n",
    "comment_parent_ids = q_jobs_comments['parent_id']\n",
    "comment_link_ids = q_jobs_comments['link_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20723"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(comment_parent_ids) - set(comment_link_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8419"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(comment_link_ids) - set(comment_parent_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21325    t1_g9tuw82\n",
       "4516     t1_ga2hj5f\n",
       "25752    t1_g9rfglv\n",
       "23539    t1_g9snrtz\n",
       "17030     t3_jgwv0u\n",
       "13691     t3_jhecjb\n",
       "9554     t1_g9zsrj7\n",
       "7050      t3_jhr6l0\n",
       "22168     t3_jgya81\n",
       "8502     t1_g9z2jql\n",
       "19892    t1_g9u9a0w\n",
       "83        t3_jh9dhm\n",
       "28912    t1_g9r8odr\n",
       "24547     t3_jgspm0\n",
       "30489     t3_jgjrof\n",
       "9085     t1_ga01hrn\n",
       "22397    t1_g9s50eo\n",
       "20898     t3_jgzwf7\n",
       "33499    t1_g9kpy3v\n",
       "15320    t1_g9wvxar\n",
       "Name: parent_id, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_parent_ids.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17511    t3_jh2ddd\n",
       "11328    t3_jh5y1y\n",
       "15283    t3_jhb1qu\n",
       "4506     t3_jh7rkj\n",
       "23812    t3_jgq2v8\n",
       "18034    t3_jh66pe\n",
       "14889    t3_jh6qga\n",
       "13144    t3_jh1sif\n",
       "7043     t3_jhppl3\n",
       "25579    t3_jgse4d\n",
       "21581    t3_jgz9bo\n",
       "12743    t3_jhbkz4\n",
       "32135    t3_jgf6bl\n",
       "5421     t3_jh7u4w\n",
       "21485    t3_jgej3a\n",
       "21607    t3_jgz4zn\n",
       "13745    t3_jh7yav\n",
       "16103    t3_jh6yw9\n",
       "3793     t3_jhx5my\n",
       "28909    t3_jgky0e\n",
       "Name: link_id, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_link_ids.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use link_id to actually link comments to submissions.\n",
    ">link_id is the submission. parent_id is the parent of the comment. It could be another comment or it could be the submission if the comment is a top level comment\n",
    "\n",
    "Will have to get submissions first, and then search for comments using that id (```link_id```) and then merge the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ji45jg'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 44)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_request_generator = api.search_comments(link_id = submission_ids[0])\n",
    "\n",
    "q_jobs_comments_1 = pd.DataFrame([submission.d_ for submission in api_request_generator])\n",
    "q_jobs_comments_1['date'] = pd.to_datetime(q_jobs_comments_1['created_utc'], utc=True, unit='s')\n",
    "q_jobs_comments_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>...</th>\n",
       "      <th>score</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>created</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Snoogins828</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>chiropractorzone</td>\n",
       "      <td>t5_hx57l</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>1.603721e+09</td>\n",
       "      <td>2020-10-26 15:01:25+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings approved_at_utc associated_award       author  \\\n",
       "0            []            None             None  Snoogins828   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text author_flair_text_color  ...  \\\n",
       "0                     None              None                    None  ...   \n",
       "\n",
       "  score send_replies  stickied         subreddit subreddit_id  \\\n",
       "0     1         True     False  chiropractorzone     t5_hx57l   \n",
       "\n",
       "  top_awarded_type total_awards_received  treatment_tags       created  \\\n",
       "0             None                     0              []  1.603721e+09   \n",
       "\n",
       "                       date  \n",
       "0 2020-10-26 15:01:25+00:00  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_comments_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2       10\n",
       "3        9\n",
       "4        0\n",
       "        ..\n",
       "6200    13\n",
       "6201     1\n",
       "6202     8\n",
       "6203     5\n",
       "6204     2\n",
       "Name: num_comments, Length: 6205, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_jobs_submissions['num_comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetrics(submissions_data):\n",
    "    \n",
    "    fig,ax = plt.figure(figsize=(12,12))\n",
    "    plt.hist(submissions_data['num_comments'])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAKrCAYAAADlINv4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAb1ElEQVR4nO3df6jl9X3n8dc7mlpJK1EyiszI6sKwWxViNoPrIixpLHWWlOo/whRah0UYCO6SQqFo/yn9Q3D/KW1gFSTJOtK0MrQNSkqylWlDWZCYsbFr1IhDdHXQdaYpoWb/sGjf+8f9phzGO++5E68z946PBxzO97zP93vne/j448mZ7z2nujsAAMD6PnKuTwAAALYywQwAAAPBDAAAA8EMAAADwQwAAIMLz/UJnM4nPvGJvvrqq8/1aQAAcB57+umn/767d6z33JYP5quvvjpHjhw516cBAMB5rKr+z6mec0kGAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADC481yewVV19z1+c61M46165/3Pn+hQAALYc7zADAMBgQ8FcVR+vqj+tqu9X1QtV9R+q6rKqeqKqXlruL13Z/96qOlpVL1bVrSvzT1fVs8tzX6yq+iBeFAAAbJaNvsP8h0m+2d3/Nsknk7yQ5J4kh7t7d5LDy+NU1bVJ9iW5LsneJA9U1QXLz3kwyYEku5fb3k16HQAA8IE4bTBX1SVJ/mOSLydJd/9Td/8oyW1JDi67HUxy+7J9W5JHu/vt7n45ydEkN1bVlUku6e4nu7uTPLJyDAAAbEkbeYf5Xyc5keR/VNV3q+pLVfWxJFd09xtJstxfvuy/M8lrK8cfW2Y7l+2T5+9RVQeq6khVHTlx4sQZvSAAANhMGwnmC5P8uyQPdvenkvy/LJdfnMJ61yX3MH/vsPuh7t7T3Xt27NixgVMEAIAPxkaC+ViSY9397eXxn2YtoN9cLrPIcn98Zf+rVo7fleT1Zb5rnTkAAGxZpw3m7v6/SV6rqn+zjG5J8nySx5PsX2b7kzy2bD+eZF9VXVRV12Ttl/ueWi7beKuqblo+HePOlWMAAGBL2ugXl/zXJF+tqp9J8oMk/zlrsX2oqu5K8mqSO5Kku5+rqkNZi+p3ktzd3e8uP+fzSR5OcnGSbyw3AADYsjYUzN39TJI96zx1yyn2vy/JfevMjyS5/gzODwAAzinf9AcAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAIMNBXNVvVJVz1bVM1V1ZJldVlVPVNVLy/2lK/vfW1VHq+rFqrp1Zf7p5eccraovVlVt/ksCAIDNcybvMP9id9/Q3XuWx/ckOdzdu5McXh6nqq5Nsi/JdUn2Jnmgqi5YjnkwyYEku5fb3vf/EgAA4IPzfi7JuC3JwWX7YJLbV+aPdvfb3f1ykqNJbqyqK5Nc0t1PdncneWTlGAAA2JI2Gsyd5C+r6umqOrDMrujuN5Jkub98me9M8trKsceW2c5l++T5e1TVgao6UlVHTpw4scFTBACAzXfhBve7ubtfr6rLkzxRVd8f9l3vuuQe5u8ddj+U5KEk2bNnz7r7AADA2bChd5i7+/Xl/niSryW5Mcmby2UWWe6PL7sfS3LVyuG7kry+zHetMwcAgC3rtMFcVR+rqp//yXaSX07yvSSPJ9m/7LY/yWPL9uNJ9lXVRVV1TdZ+ue+p5bKNt6rqpuXTMe5cOQYAALakjVyScUWSry2fAHdhkj/u7m9W1XeSHKqqu5K8muSOJOnu56rqUJLnk7yT5O7ufnf5WZ9P8nCSi5N8Y7kBAMCWddpg7u4fJPnkOvMfJrnlFMfcl+S+deZHklx/5qcJAADnhm/6AwCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgIFgBgCAgWAGAICBYAYAgMGGg7mqLqiq71bV15fHl1XVE1X10nJ/6cq+91bV0ap6sapuXZl/uqqeXZ77YlXV5r4cAADYXGfyDvMXkryw8vieJIe7e3eSw8vjVNW1SfYluS7J3iQPVNUFyzEPJjmQZPdy2/u+zh4AAD5gGwrmqtqV5HNJvrQyvi3JwWX7YJLbV+aPdvfb3f1ykqNJbqyqK5Nc0t1PdncneWTlGAAA2JI2+g7zHyT57ST/vDK7orvfSJLl/vJlvjPJayv7HVtmO5ftk+cAALBlnTaYq+pXkhzv7qc3+DPXuy65h/l6f+aBqjpSVUdOnDixwT8WAAA230beYb45ya9W1StJHk3y2ar6oyRvLpdZZLk/vux/LMlVK8fvSvL6Mt+1zvw9uvuh7t7T3Xt27NhxBi8HAAA212mDubvv7e5d3X111n6Z76+6+9eTPJ5k/7Lb/iSPLduPJ9lXVRdV1TVZ++W+p5bLNt6qqpuWT8e4c+UYAADYki58H8fen+RQVd2V5NUkdyRJdz9XVYeSPJ/knSR3d/e7yzGfT/JwkouTfGO5AQDAlnVGwdzd30ryrWX7h0luOcV+9yW5b535kSTXn+lJAgDAueKb/gAAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYCCYAQBgIJgBAGAgmAEAYHDaYK6qn62qp6rq76rquar6vWV+WVU9UVUvLfeXrhxzb1UdraoXq+rWlfmnq+rZ5bkvVlV9MC8LAAA2x0beYX47yWe7+5NJbkiyt6puSnJPksPdvTvJ4eVxquraJPuSXJdkb5IHquqC5Wc9mORAkt3Lbe/mvRQAANh8pw3mXvPj5eFHl1snuS3JwWV+MMnty/ZtSR7t7re7++UkR5PcWFVXJrmku5/s7k7yyMoxAACwJW3oGuaquqCqnklyPMkT3f3tJFd09xtJstxfvuy+M8lrK4cfW2Y7l+2T5+v9eQeq6khVHTlx4sQZvBwAANhcGwrm7n63u29Isitr7xZfP+y+3nXJPczX+/Me6u493b1nx44dGzlFAAD4QJzRp2R094+SfCtr1x6/uVxmkeX++LLbsSRXrRy2K8nry3zXOnMAANiyNvIpGTuq6uPL9sVJfinJ95M8nmT/stv+JI8t248n2VdVF1XVNVn75b6nlss23qqqm5ZPx7hz5RgAANiSLtzAPlcmObh80sVHkhzq7q9X1ZNJDlXVXUleTXJHknT3c1V1KMnzSd5Jcnd3v7v8rM8neTjJxUm+sdwAAGDLOm0wd/f/TvKpdeY/THLLKY65L8l968yPJJmufwYAgC3FN/0BAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDAQDADAMBAMAMAwEAwAwDA4LTBXFVXVdVfV9ULVfVcVX1hmV9WVU9U1UvL/aUrx9xbVUer6sWqunVl/umqenZ57otVVR/MywIAgM2xkXeY30nyW939C0luSnJ3VV2b5J4kh7t7d5LDy+Msz+1Lcl2SvUkeqKoLlp/1YJIDSXYvt72b+FoAAGDTnTaYu/uN7v7bZfutJC8k2ZnktiQHl90OJrl92b4tyaPd/XZ3v5zkaJIbq+rKJJd095Pd3UkeWTkGAAC2pDO6hrmqrk7yqSTfTnJFd7+RrEV1ksuX3XYmeW3lsGPLbOeyffIcAAC2rA0Hc1X9XJI/S/Kb3f2P067rzHqYr/dnHaiqI1V15MSJExs9RQAA2HQbCuaq+mjWYvmr3f3ny/jN5TKLLPfHl/mxJFetHL4ryevLfNc68/fo7oe6e09379mxY8dGXwsAAGy6jXxKRiX5cpIXuvv3V556PMn+ZXt/ksdW5vuq6qKquiZrv9z31HLZxltVddPyM+9cOQYAALakCzewz81JfiPJs1X1zDL7nST3JzlUVXcleTXJHUnS3c9V1aEkz2ftEzbu7u53l+M+n+ThJBcn+cZyAwCALeu0wdzd/yvrX3+cJLec4pj7kty3zvxIkuvP5AQBAOBc8k1/AAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwOG0wV9VXqup4VX1vZXZZVT1RVS8t95euPHdvVR2tqher6taV+aer6tnluS9WVW3+ywEAgM21kXeYH06y96TZPUkOd/fuJIeXx6mqa5PsS3LdcswDVXXBcsyDSQ4k2b3cTv6ZAACw5Zw2mLv7b5L8w0nj25IcXLYPJrl9Zf5od7/d3S8nOZrkxqq6Mskl3f1kd3eSR1aOAQCALeunvYb5iu5+I0mW+8uX+c4kr63sd2yZ7Vy2T56vq6oOVNWRqjpy4sSJn/IUAQDg/dvsX/pb77rkHubr6u6HuntPd+/ZsWPHpp0cAACcqZ82mN9cLrPIcn98mR9LctXKfruSvL7Md60zBwCALe2nDebHk+xftvcneWxlvq+qLqqqa7L2y31PLZdtvFVVNy2fjnHnyjEAALBlXXi6HarqT5J8JsknqupYkt9Ncn+SQ1V1V5JXk9yRJN39XFUdSvJ8kneS3N3d7y4/6vNZ+8SNi5N8Y7kBAMCWdtpg7u5fO8VTt5xi//uS3LfO/EiS68/o7AAA4BzzTX8AADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwEMwAADAQzAAAMBDMAAAwuPBcnwBbx9X3/MW5PoWz7pX7P3euTwEA2OK8wwwAAAPBDAAAA8EMAAADwQwAAAPBDAAAA8EMAACDs/6xclW1N8kfJrkgyZe6+/6zfQ7wEz5KDwA4nbP6DnNVXZDkvyf5T0muTfJrVXXt2TwHAAA4E2f7HeYbkxzt7h8kSVU9muS2JM+f5fOAD60P47vqnP/8zcmHw4fxv1/+2d4aznYw70zy2srjY0n+/ck7VdWBJAeWhz+uqhfPwrmd7BNJ/v4c/Ll8cKzp+cV6nl/e13rWf9vEM2Gz+Hd0E2yhf7Y/DOv5r071xNkO5lpn1u8ZdD+U5KEP/nROraqOdPeec3kObC5ren6xnucX63n+sabnlw/7ep7tT8k4luSqlce7krx+ls8BAAA27GwH83eS7K6qa6rqZ5LsS/L4WT4HAADYsLN6SUZ3v1NV/yXJ/8zax8p9pbufO5vncAbO6SUhfCCs6fnFep5frOf5x5qeXz7U61nd77mEGAAAWPimPwAAGAhmAAAYCOZ1VNXeqnqxqo5W1T3n+nw4var6SlUdr6rvrcwuq6onquql5f7SlefuXdb3xaq69dycNadSVVdV1V9X1QtV9VxVfWGZW9NtqKp+tqqeqqq/W9bz95a59dzmquqCqvpuVX19eWxNt6mqeqWqnq2qZ6rqyDKzngvBfBJf371tPZxk70mze5Ic7u7dSQ4vj7Os574k1y3HPLCsO1vHO0l+q7t/IclNSe5e1s2abk9vJ/lsd38yyQ1J9lbVTbGe54MvJHlh5bE13d5+sbtvWPm8Zeu5EMzv9S9f393d/5TkJ1/fzRbW3X+T5B9OGt+W5OCyfTDJ7SvzR7v77e5+OcnRrK07W0R3v9Hdf7tsv5W1/yHvjDXdlnrNj5eHH11uHeu5rVXVriSfS/KllbE1Pb9Yz4Vgfq/1vr575zk6F96fK7r7jWQtwJJcvsyt8TZSVVcn+VSSb8eablvLX90/k+R4kie623puf3+Q5LeT/PPKzJpuX53kL6vq6ao6sMys5+JsfzX2drChr+9mW7PG20RV/VySP0vym939j1XrLd3aruvMrOkW0t3vJrmhqj6e5GtVdf2wu/Xc4qrqV5Ic7+6nq+ozGzlknZk13Vpu7u7Xq+ryJE9U1feHfT906+kd5vfy9d3njzer6sokWe6PL3NrvA1U1UezFstf7e4/X8bWdJvr7h8l+VbWrnu0ntvXzUl+tapeydqli5+tqj+KNd22uvv15f54kq9l7RIL67kQzO/l67vPH48n2b9s70/y2Mp8X1VdVFXXJNmd5KlzcH6cQq29lfzlJC909++vPGVNt6Gq2rG8s5yqujjJLyX5fqznttXd93b3ru6+Omv/n/yr7v71WNNtqao+VlU//5PtJL+c5Huxnv/CJRkn2WZf382iqv4kyWeSfKKqjiX53ST3JzlUVXcleTXJHUnS3c9V1aEkz2ft0xjuXv66mK3j5iS/keTZ5brXJPmdWNPt6sokB5ffov9IkkPd/fWqejLW83zj39Ht6YqsXSqVrLXhH3f3N6vqO7GeSXw1NgAAjFySAQAAA8EMAAADwQwAAAPBDAAAA8EMAAADwQwAAAPBDAAAg/8PgPKk5zmeJBUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotMetrics(q_jobs_submissions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditScrapper",
   "language": "python",
   "name": "redditscrapper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
