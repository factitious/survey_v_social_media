{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning\n",
    "\n",
    "### Things that need to be done    \n",
    "\n",
    "- [x] Set up skeleton for a nice object oriented approach. \n",
    "- [x] Figure out best way to get tweets.\n",
    "- [x] Data format\n",
    "- [x] Build class and funcs\n",
    "- [ ] Figure out how to best count all requests in a session and make sure it's functional\n",
    "- [ ] Make oneDay() fail safe (it's a bad idea to get the data and combine it within a single for, because if something goes wrong in an interation all the data from previous iterations will be lost if something goes wrong).\n",
    "- [ ] Save metadata for the payloads (i.e. self.most_recent, self.oldest, self.timeCovered, rs.total_results + other?)\n",
    "\n",
    "### Rate Limits\n",
    "\n",
    "- 10,000,000 Tweets per month (resets on the 19th of each month). \n",
    "- 300 requests/15 minute window, with 500 Tweets/request:\n",
    "    - 150,000 tweets/15min \n",
    "    - 600,000 tweets/hour\n",
    "\n",
    "### How many tweets to get?\n",
    "- Period covered is: Oct 23rd - July 30th (-ish)\n",
    "    - ~ 280 days\n",
    "    - ~ 6720 hours\n",
    "    - If we get 1000 tweets per hour: *6,720,000*. \n",
    "    - That's very little in terms of space, but might take quite a while for it to go through sentiment analysis.\n",
    "    - It would take ~11.2 hours to get the whole data (due to rate limits)\n",
    "\n",
    "### Best way to get tweets\n",
    "- Period covered is: Oct 23rd - July 30th (-ish)\n",
    "    - $n_h$ per hour/day\n",
    "    - $n_d$ per day (where n_d would be ~ $n_h*24$)\n",
    "    \n",
    "\n",
    "- While it makes the wrangling a bit more difficult, I think it might be interesting to look at hour/day. \n",
    "- We can still combine all tweets for a given day. \n",
    "\n",
    "### Data format\n",
    "\n",
    "- A single results call: **JSON to pd**.\n",
    "    - This is relatively straightforward with one minor complication, i.e. entries such as this:\n",
    "    <blockquote>{'newest_id': '1402310241992183808',\n",
    "  'oldest_id': '1402310139630211083',\n",
    "  'result_count': 100,\n",
    "  'next_token': 'b26v89c19zqg8o3fpdg7rbcqdq8stpgmibslekg3kxail'}\n",
    "    </blockquote>\n",
    "    - This is used by the wrapper to get the next lot of tweets if max_tweets > results_per_call, but will also always be the last entry in a result.\n",
    "    \n",
    "    \n",
    "- Multiple results calls: **pds in dict-of-dict**. \n",
    "    - I am thinking the best way to store all the data would be a dict-of-dict, but will see how it works  \n",
    "\n",
    "To start with, get 10 tweets/hour from the start period (23.10.2020) to the most recent available HPS data. As of now (08.06.2021) this is 24.05.2021 for the Axios-Ipsos survey. This means: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev\n",
    "\n",
    "To start with, get 10 tweets/hour from the start period (23.10.2020) to the most recent available HPS data. As of now (08.06.2021) this is 24.05.2021 for the Axios-Ipsos survey. This means: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "import time\n",
    "from os import path\n",
    "from searchtweets import ResultStream, gen_request_parameters, load_credentials, collect_results, convert_utc_time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2020-10-23 to 2021-05-24 we have 213 days, 5112 hours, and 51120 tweets (with 10 tweets per hour)\n"
     ]
    }
   ],
   "source": [
    "def countTweets(startDate, endDate, tweets_per_hour):\n",
    "    '''\n",
    "    Specify dates in DD.MM.YYY format (no leading 0 for months or days)\n",
    "    '''\n",
    "    \n",
    "    s_d, s_m, s_y = [ int(i) for i in startDate.split('.')]\n",
    "    e_d, e_m, e_y = [ int(i) for i in endDate.split('.')]\n",
    "\n",
    "    endDate = date(e_y, e_m, e_d)\n",
    "    startDate = date(s_y, s_m, s_d)\n",
    "    days = endDate-startDate\n",
    "    print(\"From {} to {} we have {} days, {} hours, and {} tweets (with {} tweets per hour)\".format(startDate, \n",
    "                                                                                                    endDate, \n",
    "                                                                                                    days.days, \n",
    "                                                                                                    days.days*24, \n",
    "                                                                                                   days.days*24*tweets_per_hour,\n",
    "                                                                                                   tweets_per_hour))\n",
    "    \n",
    "    \n",
    "countTweets('23.10.2020', '24.05.2021', 10)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is quite manageable.\n",
    "\n",
    "However, it might be better to get a more complete set for a shorter period of time. So let's do 26.10.2020 - 01.11.2020. This would mean 216000 tweets, but this can actually be used going forward, so that future data collection can just start on 01.11.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 2020-10-23 to 2020-11-01 we have 9 days, 216 hours, and 216000 tweets (with 1000 tweets per hour)\n"
     ]
    }
   ],
   "source": [
    "countTweets('23.10.2020', '1.11.2020', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class twitterData():\n",
    "    '''\n",
    "    The acronym from the full title of the project is UCBSMASD. If we ignore the \"C\" this \n",
    "    can be unscrambled to DUMBASS, so I couldn't help it.\n",
    "    \n",
    "    A class for holding all the Twitter search related elements, from validating credentials\n",
    "    to getting/cleaning the data.\n",
    "    '''\n",
    "        \n",
    "    def __init__(self, main_path):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        self.main_path = main_path # /Volumes/Survey_Social_Media_Compare/Methods/Scripts/Twitter/\n",
    "    \n",
    "    def validate_credentials(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        c_path = path.join(self.main_path, 'twitter_keys.yaml')\n",
    "        self.credentials = load_credentials('/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Twitter/twitter_keys.yaml', \n",
    "                                       env_overwrite=True);\n",
    "        self.all_requests = 0;\n",
    "\n",
    "        return \"Credentials validated successfully\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    def build_query(self,\n",
    "                    mainTerms, \n",
    "                    startDate,\n",
    "                    endDate,\n",
    "                    inQuotes = True, \n",
    "                    language = 'en', \n",
    "                    country = 'US',\n",
    "                    excludeRT = False,\n",
    "                    results_per_call = 500,\n",
    "                    return_fields = 'id,created_at,text,public_metrics',\n",
    "                    otherTerms = []):\n",
    "        \n",
    "        '''\n",
    "        Builds the query that is used to make the requests and get payloads.\n",
    "        \n",
    "        Parameters:\n",
    "            mainTerms (str): The search terms we want, e.g. 'jobs'\n",
    "            startDate (str): The lower end of the period we are interested in YYY-MM-DD HH:MM format, \n",
    "                             e.g. '2020-10-23 13:00'\n",
    "            endDate (str): The higher end of the period we are interested in in YYY-MM-DD HH:MM format, \n",
    "                             e.g. '2020-10-23 14:00'\n",
    "            inQuotes (bool): Do we want an exact phrase match? If true the terms will be put in quotes\n",
    "            language (str): Language used in the query (only languages supported by Twitter + \n",
    "                            has to be in the correct format, see https://bit.ly/2RBwmGa)\n",
    "            country (str): Country where Tweet/User is located (has to be in the correct format, see\n",
    "                            https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2)\n",
    "            excludeRT (bool): Exclude retweets from the payload? Default False\n",
    "            results_per_call (int): How many results per request? Max is 500 for the academic API.\n",
    "            otherTerms (list): List of other search terms, e.g. ['#COVID', 'is:reply']\n",
    "        \n",
    "        Notes:\n",
    "            - tweets are fetched in reverse chronological order, i.e. starting at endDate \n",
    "            and continuing until a limit is reached.\n",
    "            - endDate refers to previous day until 23:59\n",
    "        '''\n",
    "        \n",
    "        # If excluding retweets, set rt to '-' \n",
    "        rt = '-is:retweet' if excludeRT == True else ''\n",
    "        \n",
    "        # Are the terms in quotes\n",
    "        mainTerms = '\"{}\"'.format(mainTerms) if inQuotes == True else '{}'\n",
    "        \n",
    "        # Build query text\n",
    "        queryText = '{} lang: {} place_country:{}'.format(mainTerms,\n",
    "                                                         language,\n",
    "                                                         country)\n",
    "        \n",
    "        # If there are other terms, include them in the queryText\n",
    "        queryText = queryText.extend(other) if otherTerms != [] else queryText\n",
    "        \n",
    "        # Save these as will be used to determine limits\n",
    "        self.results_per_call = results_per_call\n",
    "        self.startDate = startDate\n",
    "        self.endDate = endDate\n",
    "            \n",
    "        # Build query\n",
    "        self.query = gen_request_parameters(queryText,\n",
    "                                      start_time = self.startDate,\n",
    "                                      end_time = self.endDate,\n",
    "                                      tweet_fields = return_fields,\n",
    "                                      results_per_call = self.results_per_call)\n",
    "        \n",
    "        return self.query\n",
    "    \n",
    "    def get_data(self, nTweets = 500):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        #\n",
    "        self.rs = ResultStream(request_parameters = self.query,\n",
    "                                  max_tweets = nTweets,\n",
    "                                  output_format = \"a\",\n",
    "                                  **self.credentials)\n",
    "        \n",
    "        self.result = list(self.rs.stream())\n",
    "        \n",
    "        # We can get the total requests made for a payload using:\n",
    "        # twitterData_instance.rs.n_requests\n",
    "        # twitterData_instance.rs.session_request_counter\n",
    "        \n",
    "        # This can be used to get the overall requests made\n",
    "        self.all_requests += self.rs.session_request_counter       \n",
    "        \n",
    "        \n",
    "    \n",
    "    def wait_time():\n",
    "        '''\n",
    "        Figure out how long you have to wait, and after how many requests, to avoid \n",
    "        rate limit issues.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def get_df(self):\n",
    "        '''\n",
    "        '''\n",
    "        # Remove the entries (i.e. dictionaries) that contain\n",
    "        # the key 'newest_id' from the payload, i.e. the result \n",
    "        # of our query (which is a list of dictionaries).        \n",
    "        clean_json_list = [x for x in self.result if 'newest_id' not in x]        \n",
    "        \n",
    "        df = pd.json_normalize(clean_json_list)\n",
    "\n",
    "        # Calculate the time covered in a payload.\n",
    "        # Most recent date/time in the df in datetime format\n",
    "        self.most_recent = twitterData.toDatetime(max(self.df['created_at']))\n",
    "        self.oldest = twitterData.toDatetime(min(self.df['created_at']))\n",
    "        \n",
    "        self.timeCovered = (self.most_recent - self.oldest).seconds\n",
    "        \n",
    "\n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def oneDay(self,date):\n",
    "        '''\n",
    "        Get the df for every hour and combine into a single dataframe. \n",
    "        '''\n",
    "        \n",
    "        init_request_session = time.time()\n",
    "        \n",
    "        # Hours in the day\n",
    "        t = ['{}:00'.format(x) for x in range(0,24)]\n",
    "        \n",
    "        # For every hour (of 24)\n",
    "        for i in range(24):\n",
    "            \n",
    "            # Determine start and end time, e.g. '2020-10-23 00:00' abd '2020-10-23 01:00' \n",
    "            startTime = '{} {}'.format(date, t[i]) \n",
    "            \n",
    "            if i==23:\n",
    "                endDate = '{} {}'.format(date, '23:59') \n",
    "            else:\n",
    "                endDate = '{} {}'.format(date, t[i+1]) \n",
    "\n",
    "            # Build the query\n",
    "            self.build_query('jobs', startDate, endDate, results_per_call=500)\n",
    "            \n",
    "            \n",
    "            # If the next request is the 300th (or multiple thereof)\n",
    "            # and we are within the same 15 min window.\n",
    "            # TODO: This is no good, as all_requests is not incremented by 1 (but by 3-30ish on every call)\n",
    "            if (self.all_requests+1 % 300 != 0) and (time.time() - init_request_session < 900):\n",
    "                \n",
    "                # Get the data (up to 1000 results per hour)\n",
    "                self.get_data(nTweets = 1000)\n",
    "                \n",
    "            else:\n",
    "                # Sleep for 15 minutes minus however long we had in this session\n",
    "                time.sleep(900 - (time.time() - init_request_session))\n",
    "                \n",
    "                # Then get the data\n",
    "                self.get_data(nTweets = 1000)\n",
    "                \n",
    "                # And reset the session timer\n",
    "                init_request_session = time.time()\n",
    "                \n",
    "            \n",
    "            # Clean data\n",
    "            current_df = self.get_df()\n",
    "            \n",
    "            # Add to dataframe containing the data for a single day.\n",
    "            if i == 1:\n",
    "                all_day_df = current_df\n",
    "                \n",
    "            else:\n",
    "                all_day_df = pd.concat([all_day_df, current_df])\n",
    "\n",
    "        \n",
    "    \n",
    "    def exportOneDay():\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def exportOneDay():\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def toDatetime(dateStr):\n",
    "        '''\n",
    "        Take a date in the ISO format that we get from twitter \"%Y-%m-%dT%H:%M:%S.000Z\"\n",
    "        and transform to a datetime for calculations.\n",
    "\n",
    "        Parameters:\n",
    "            dateStr (str): A date string (ISO format)\n",
    "        \n",
    "        Returns:\n",
    "            dateDT (datetime): A datetime object  \n",
    "        '''\n",
    "        \n",
    "        dateDT = datetime.strptime(dateStr, \"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "        \n",
    "        return dateDT\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 1:00\n",
      "1:00 2:00\n",
      "2:00 3:00\n",
      "3:00 4:00\n",
      "4:00 5:00\n",
      "5:00 6:00\n",
      "6:00 7:00\n",
      "7:00 8:00\n",
      "8:00 9:00\n",
      "9:00 10:00\n",
      "10:00 11:00\n",
      "11:00 12:00\n",
      "12:00 13:00\n",
      "13:00 14:00\n",
      "14:00 15:00\n",
      "15:00 16:00\n",
      "16:00 17:00\n",
      "17:00 18:00\n",
      "18:00 19:00\n",
      "19:00 20:00\n",
      "20:00 21:00\n",
      "21:00 22:00\n",
      "22:00 23:00\n",
      "23:00 23:59\n"
     ]
    }
   ],
   "source": [
    "t = ['{}:00'.format(x) for x in range(0,24)]\n",
    "\n",
    "for i in range(24):\n",
    "    \n",
    "    if i == 23:\n",
    "        print(t[i], '23:59')\n",
    "    else:\n",
    "        print(t[i], t[i+1])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(t[i-1], t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#00:00\n",
    "#01:00\n",
    "#02:00\n",
    "#03:00\n",
    "#...\n",
    "#10:00\n",
    "\n",
    "t = ['{}:00'.format(x) for x in range(0,24)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Credentials validated successfully'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1 = twitterData('/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Twitter/')\n",
    "search1.validate_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.build_query('jobs','2020-10-23 00:00', '2020-10-23 01:00', results_per_call=500)\n",
    "search1.get_data(nTweets = 1000)\n",
    "df1 = search1.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.build_query('jobs','2020-10-23 01:00', '2020-10-23 2:00', results_per_call=500)\n",
    "search1.get_data(nTweets = 1000)\n",
    "df2 = search1.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.build_query('jobs','2020-10-23 23:00', '2020-10-23 23:59', results_per_call=500)\n",
    "search1.get_data(nTweets = 1000)\n",
    "df3 = search1.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes we are! Thankful and blessed for all our B...</td>\n",
       "      <td>1319789833443811328</td>\n",
       "      <td>2020-10-23T23:56:31.000Z</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White people always saying that Mexicans are s...</td>\n",
       "      <td>1319789469516455938</td>\n",
       "      <td>2020-10-23T23:55:04.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Interested in a job in #Aurora, COLORADO? This...</td>\n",
       "      <td>1319788560044552195</td>\n",
       "      <td>2020-10-23T23:51:27.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@DangerousDC40 @washingtonpost There will be o...</td>\n",
       "      <td>1319788306390016002</td>\n",
       "      <td>2020-10-23T23:50:27.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y’all, we are hiring!  Head to our website htt...</td>\n",
       "      <td>1319787829606686728</td>\n",
       "      <td>2020-10-23T23:48:33.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@MSNBC He’s 100% correct. Transitioning out of...</td>\n",
       "      <td>1319787776125112325</td>\n",
       "      <td>2020-10-23T23:48:20.000Z</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@realDonaldTrump New energy saving jobs, bette...</td>\n",
       "      <td>1319787715152416768</td>\n",
       "      <td>2020-10-23T23:48:06.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@GeorgeTakei Rural voters fear transitioning t...</td>\n",
       "      <td>1319787231989669888</td>\n",
       "      <td>2020-10-23T23:46:11.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just had a whole conversation with myself .\\...</td>\n",
       "      <td>1319786495130038272</td>\n",
       "      <td>2020-10-23T23:43:15.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Want to work in #Orange, CA? View our latest o...</td>\n",
       "      <td>1319785407962255360</td>\n",
       "      <td>2020-10-23T23:38:56.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@_realanna @AnnieTangent And now the teachers ...</td>\n",
       "      <td>1319784709120024576</td>\n",
       "      <td>2020-10-23T23:36:09.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Renewable energy will create jobs and save our...</td>\n",
       "      <td>1319783879969046531</td>\n",
       "      <td>2020-10-23T23:32:52.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Why I be reciting @citygirls jobs like it’s a ...</td>\n",
       "      <td>1319783646170017792</td>\n",
       "      <td>2020-10-23T23:31:56.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DJT is sadly ignorant of the what jobs the Gre...</td>\n",
       "      <td>1319783055465218048</td>\n",
       "      <td>2020-10-23T23:29:35.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>President Trump supports and understands the p...</td>\n",
       "      <td>1319782437971394560</td>\n",
       "      <td>2020-10-23T23:27:08.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Get it Get it #upsishiring https://t.co/mBIGxj...</td>\n",
       "      <td>1319782433965936641</td>\n",
       "      <td>2020-10-23T23:27:07.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@JoeBiden If obama and biden did such a great ...</td>\n",
       "      <td>1319781911284375552</td>\n",
       "      <td>2020-10-23T23:25:02.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How many jobs could renewables create?  No pos...</td>\n",
       "      <td>1319781827838726144</td>\n",
       "      <td>2020-10-23T23:24:42.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Working in a contact center with only older wo...</td>\n",
       "      <td>1319781379572404224</td>\n",
       "      <td>2020-10-23T23:22:55.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@Quickpul_triger @__cgo41 @NewFly_G @kgaleas_2...</td>\n",
       "      <td>1319781355610378240</td>\n",
       "      <td>2020-10-23T23:22:50.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@MollyJongFast Obama/Biden added 1.5 million M...</td>\n",
       "      <td>1319781342523973632</td>\n",
       "      <td>2020-10-23T23:22:47.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@Quickpul_triger @__cgo41 @NewFly_G @kgaleas_2...</td>\n",
       "      <td>1319780079313035264</td>\n",
       "      <td>2020-10-23T23:17:45.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.@townsquaretalk I didn’t make it on the show ...</td>\n",
       "      <td>1319780060304429056</td>\n",
       "      <td>2020-10-23T23:17:41.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.@townsquaretalk I didn’t make it on the show ...</td>\n",
       "      <td>1319779951311282176</td>\n",
       "      <td>2020-10-23T23:17:15.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.@townsquaretalk I didn’t make it on the show ...</td>\n",
       "      <td>1319779777260277763</td>\n",
       "      <td>2020-10-23T23:16:33.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>But CEOs are still trying to send corporate jo...</td>\n",
       "      <td>1319779388754448384</td>\n",
       "      <td>2020-10-23T23:15:01.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Imagine being rude to some one who cant do any...</td>\n",
       "      <td>1319779149666570243</td>\n",
       "      <td>2020-10-23T23:14:04.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Messed up we do the jobs no one else wants to ...</td>\n",
       "      <td>1319778861949751296</td>\n",
       "      <td>2020-10-23T23:12:55.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Not only Mexicans but all immigrants regardles...</td>\n",
       "      <td>1319778540661866496</td>\n",
       "      <td>2020-10-23T23:11:39.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I’ve applied for 68 jobs in the last 2 months ...</td>\n",
       "      <td>1319778143788552193</td>\n",
       "      <td>2020-10-23T23:10:04.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@grizwald87 @jdcmedlock It's not about sustain...</td>\n",
       "      <td>1319777908769067008</td>\n",
       "      <td>2020-10-23T23:09:08.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>@JoeBiden Eight years of obama and biden and w...</td>\n",
       "      <td>1319777604271038464</td>\n",
       "      <td>2020-10-23T23:07:55.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>@kayleighmcenany @realDonaldTrump Funny how an...</td>\n",
       "      <td>1319776328518914048</td>\n",
       "      <td>2020-10-23T23:02:51.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ion know why all my jobs play with me</td>\n",
       "      <td>1319775718742593537</td>\n",
       "      <td>2020-10-23T23:00:26.000Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>People in your state are dying of COVID-19, wh...</td>\n",
       "      <td>1319775677353254912</td>\n",
       "      <td>2020-10-23T23:00:16.000Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                   id  \\\n",
       "0   Yes we are! Thankful and blessed for all our B...  1319789833443811328   \n",
       "1   White people always saying that Mexicans are s...  1319789469516455938   \n",
       "2   Interested in a job in #Aurora, COLORADO? This...  1319788560044552195   \n",
       "3   @DangerousDC40 @washingtonpost There will be o...  1319788306390016002   \n",
       "4   Y’all, we are hiring!  Head to our website htt...  1319787829606686728   \n",
       "5   @MSNBC He’s 100% correct. Transitioning out of...  1319787776125112325   \n",
       "6   @realDonaldTrump New energy saving jobs, bette...  1319787715152416768   \n",
       "7   @GeorgeTakei Rural voters fear transitioning t...  1319787231989669888   \n",
       "8   I just had a whole conversation with myself .\\...  1319786495130038272   \n",
       "9   Want to work in #Orange, CA? View our latest o...  1319785407962255360   \n",
       "10  @_realanna @AnnieTangent And now the teachers ...  1319784709120024576   \n",
       "11  Renewable energy will create jobs and save our...  1319783879969046531   \n",
       "12  Why I be reciting @citygirls jobs like it’s a ...  1319783646170017792   \n",
       "13  DJT is sadly ignorant of the what jobs the Gre...  1319783055465218048   \n",
       "14  President Trump supports and understands the p...  1319782437971394560   \n",
       "15  Get it Get it #upsishiring https://t.co/mBIGxj...  1319782433965936641   \n",
       "16  @JoeBiden If obama and biden did such a great ...  1319781911284375552   \n",
       "17  How many jobs could renewables create?  No pos...  1319781827838726144   \n",
       "18  Working in a contact center with only older wo...  1319781379572404224   \n",
       "19  @Quickpul_triger @__cgo41 @NewFly_G @kgaleas_2...  1319781355610378240   \n",
       "20  @MollyJongFast Obama/Biden added 1.5 million M...  1319781342523973632   \n",
       "21  @Quickpul_triger @__cgo41 @NewFly_G @kgaleas_2...  1319780079313035264   \n",
       "22  .@townsquaretalk I didn’t make it on the show ...  1319780060304429056   \n",
       "23  .@townsquaretalk I didn’t make it on the show ...  1319779951311282176   \n",
       "24  .@townsquaretalk I didn’t make it on the show ...  1319779777260277763   \n",
       "25  But CEOs are still trying to send corporate jo...  1319779388754448384   \n",
       "26  Imagine being rude to some one who cant do any...  1319779149666570243   \n",
       "27  Messed up we do the jobs no one else wants to ...  1319778861949751296   \n",
       "28  Not only Mexicans but all immigrants regardles...  1319778540661866496   \n",
       "29  I’ve applied for 68 jobs in the last 2 months ...  1319778143788552193   \n",
       "30  @grizwald87 @jdcmedlock It's not about sustain...  1319777908769067008   \n",
       "31  @JoeBiden Eight years of obama and biden and w...  1319777604271038464   \n",
       "32  @kayleighmcenany @realDonaldTrump Funny how an...  1319776328518914048   \n",
       "33              Ion know why all my jobs play with me  1319775718742593537   \n",
       "34  People in your state are dying of COVID-19, wh...  1319775677353254912   \n",
       "\n",
       "                  created_at  public_metrics.retweet_count  \\\n",
       "0   2020-10-23T23:56:31.000Z                             3   \n",
       "1   2020-10-23T23:55:04.000Z                             1   \n",
       "2   2020-10-23T23:51:27.000Z                             0   \n",
       "3   2020-10-23T23:50:27.000Z                             0   \n",
       "4   2020-10-23T23:48:33.000Z                             1   \n",
       "5   2020-10-23T23:48:20.000Z                             5   \n",
       "6   2020-10-23T23:48:06.000Z                             0   \n",
       "7   2020-10-23T23:46:11.000Z                             0   \n",
       "8   2020-10-23T23:43:15.000Z                             0   \n",
       "9   2020-10-23T23:38:56.000Z                             0   \n",
       "10  2020-10-23T23:36:09.000Z                             0   \n",
       "11  2020-10-23T23:32:52.000Z                             0   \n",
       "12  2020-10-23T23:31:56.000Z                             0   \n",
       "13  2020-10-23T23:29:35.000Z                             0   \n",
       "14  2020-10-23T23:27:08.000Z                             0   \n",
       "15  2020-10-23T23:27:07.000Z                             0   \n",
       "16  2020-10-23T23:25:02.000Z                             0   \n",
       "17  2020-10-23T23:24:42.000Z                             0   \n",
       "18  2020-10-23T23:22:55.000Z                             0   \n",
       "19  2020-10-23T23:22:50.000Z                             0   \n",
       "20  2020-10-23T23:22:47.000Z                             1   \n",
       "21  2020-10-23T23:17:45.000Z                             0   \n",
       "22  2020-10-23T23:17:41.000Z                             0   \n",
       "23  2020-10-23T23:17:15.000Z                             1   \n",
       "24  2020-10-23T23:16:33.000Z                             0   \n",
       "25  2020-10-23T23:15:01.000Z                             0   \n",
       "26  2020-10-23T23:14:04.000Z                             0   \n",
       "27  2020-10-23T23:12:55.000Z                             2   \n",
       "28  2020-10-23T23:11:39.000Z                             0   \n",
       "29  2020-10-23T23:10:04.000Z                             0   \n",
       "30  2020-10-23T23:09:08.000Z                             0   \n",
       "31  2020-10-23T23:07:55.000Z                             0   \n",
       "32  2020-10-23T23:02:51.000Z                             0   \n",
       "33  2020-10-23T23:00:26.000Z                             0   \n",
       "34  2020-10-23T23:00:16.000Z                             1   \n",
       "\n",
       "    public_metrics.reply_count  public_metrics.like_count  \\\n",
       "0                            0                         23   \n",
       "1                            0                          0   \n",
       "2                            0                          0   \n",
       "3                            0                          0   \n",
       "4                            0                          2   \n",
       "5                            2                          9   \n",
       "6                            0                          0   \n",
       "7                            0                          1   \n",
       "8                            0                          1   \n",
       "9                            0                          0   \n",
       "10                           0                          1   \n",
       "11                           0                          2   \n",
       "12                           0                          0   \n",
       "13                           0                          0   \n",
       "14                           0                          0   \n",
       "15                           0                          1   \n",
       "16                           0                          0   \n",
       "17                           0                          0   \n",
       "18                           1                          1   \n",
       "19                           1                          0   \n",
       "20                           0                          2   \n",
       "21                           2                          0   \n",
       "22                           0                          1   \n",
       "23                           0                          0   \n",
       "24                           0                          2   \n",
       "25                           0                          4   \n",
       "26                           1                          5   \n",
       "27                           0                          6   \n",
       "28                           0                          2   \n",
       "29                           1                          7   \n",
       "30                           1                          0   \n",
       "31                           0                          0   \n",
       "32                           0                          2   \n",
       "33                           0                          0   \n",
       "34                           0                          1   \n",
       "\n",
       "    public_metrics.quote_count  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "5                            1  \n",
       "6                            0  \n",
       "7                            0  \n",
       "8                            0  \n",
       "9                            0  \n",
       "10                           0  \n",
       "11                           0  \n",
       "12                           0  \n",
       "13                           0  \n",
       "14                           0  \n",
       "15                           0  \n",
       "16                           0  \n",
       "17                           0  \n",
       "18                           0  \n",
       "19                           0  \n",
       "20                           0  \n",
       "21                           0  \n",
       "22                           0  \n",
       "23                           0  \n",
       "24                           0  \n",
       "25                           0  \n",
       "26                           0  \n",
       "27                           0  \n",
       "28                           0  \n",
       "29                           1  \n",
       "30                           0  \n",
       "31                           0  \n",
       "32                           0  \n",
       "33                           0  \n",
       "34                           0  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319458440633339904</td>\n",
       "      <td>2020-10-23T01:59:41.000Z</td>\n",
       "      <td>Many of the jobs lost this year will never com...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319458438943019009</td>\n",
       "      <td>2020-10-23T01:59:40.000Z</td>\n",
       "      <td>I have a 401K and investments. I like seeing t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1319458252460085249</td>\n",
       "      <td>2020-10-23T01:58:56.000Z</td>\n",
       "      <td>You’re all sitting here while you’re still all...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1319458198932381697</td>\n",
       "      <td>2020-10-23T01:58:43.000Z</td>\n",
       "      <td>In case you didn’t know this, the stock market...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1319458079759568896</td>\n",
       "      <td>2020-10-23T01:58:15.000Z</td>\n",
       "      <td>@Jaycaleb8 Bro what are you saying, I live dow...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1319444682720661504</td>\n",
       "      <td>2020-10-23T01:05:01.000Z</td>\n",
       "      <td>Looking forward to hearing @JoeBiden talk abou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1319444365014609920</td>\n",
       "      <td>2020-10-23T01:03:45.000Z</td>\n",
       "      <td>If Biden thinks Trump mishandled Covid 19 he n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1319444125972914176</td>\n",
       "      <td>2020-10-23T01:02:48.000Z</td>\n",
       "      <td>@rrt003 @MSNBC @DailyNewsSA Well no. Also how ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1319443992451248129</td>\n",
       "      <td>2020-10-23T01:02:16.000Z</td>\n",
       "      <td>Gays dont not liking Trump as a person. Ooohh ...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1319443807641825280</td>\n",
       "      <td>2020-10-23T01:01:32.000Z</td>\n",
       "      <td>@LindseyGrahamSC All economists say @JoeBiden ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                created_at  \\\n",
       "0   1319458440633339904  2020-10-23T01:59:41.000Z   \n",
       "1   1319458438943019009  2020-10-23T01:59:40.000Z   \n",
       "2   1319458252460085249  2020-10-23T01:58:56.000Z   \n",
       "3   1319458198932381697  2020-10-23T01:58:43.000Z   \n",
       "4   1319458079759568896  2020-10-23T01:58:15.000Z   \n",
       "..                  ...                       ...   \n",
       "58  1319444682720661504  2020-10-23T01:05:01.000Z   \n",
       "59  1319444365014609920  2020-10-23T01:03:45.000Z   \n",
       "60  1319444125972914176  2020-10-23T01:02:48.000Z   \n",
       "61  1319443992451248129  2020-10-23T01:02:16.000Z   \n",
       "62  1319443807641825280  2020-10-23T01:01:32.000Z   \n",
       "\n",
       "                                                 text  \\\n",
       "0   Many of the jobs lost this year will never com...   \n",
       "1   I have a 401K and investments. I like seeing t...   \n",
       "2   You’re all sitting here while you’re still all...   \n",
       "3   In case you didn’t know this, the stock market...   \n",
       "4   @Jaycaleb8 Bro what are you saying, I live dow...   \n",
       "..                                                ...   \n",
       "58  Looking forward to hearing @JoeBiden talk abou...   \n",
       "59  If Biden thinks Trump mishandled Covid 19 he n...   \n",
       "60  @rrt003 @MSNBC @DailyNewsSA Well no. Also how ...   \n",
       "61  Gays dont not liking Trump as a person. Ooohh ...   \n",
       "62  @LindseyGrahamSC All economists say @JoeBiden ...   \n",
       "\n",
       "    public_metrics.retweet_count  public_metrics.reply_count  \\\n",
       "0                              0                           1   \n",
       "1                              0                           1   \n",
       "2                              0                           0   \n",
       "3                              0                           0   \n",
       "4                              0                           1   \n",
       "..                           ...                         ...   \n",
       "58                             0                           0   \n",
       "59                             0                           0   \n",
       "60                             0                           1   \n",
       "61                             2                           4   \n",
       "62                             0                           0   \n",
       "\n",
       "    public_metrics.like_count  public_metrics.quote_count  \n",
       "0                           2                           0  \n",
       "1                           1                           0  \n",
       "2                           0                           0  \n",
       "3                           1                           0  \n",
       "4                           0                           0  \n",
       "..                        ...                         ...  \n",
       "58                          2                           0  \n",
       "59                          0                           0  \n",
       "60                          1                           0  \n",
       "61                         40                           1  \n",
       "62                          0                           0  \n",
       "\n",
       "[63 rows x 7 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.rs.session_request_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.all_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.all_requests2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For vaccines, 1650 tweets appear to be getting all the results from a 24 hour window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query\": \"\\\\\"jobs\\\\\" lang: en place_country:US\", \"max_results\": 500, \"start_time\": \"2021-02-16T00:00:00Z\", \"end_time\": \"2021-02-17T00:00:00Z\", \"tweet.fields\": \"id,created_at,text,public_metrics\"}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2 = twitterData('/Volumes/Survey_Social_Media_Compare/Methods/Scripts/Twitter/')\n",
    "search2.validate_credentials()\n",
    "search2.build_query('jobs','2021-2-16', '2021-2-17', results_per_call=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In execute_request\n",
      "\n",
      "\n",
      "\n",
      "In execute_request\n",
      "\n",
      "\n",
      "\n",
      "In stream\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search2.get_data(nTweets=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(search2.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 15, 0, 1, 14)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.oldest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 15, 23, 59, 44)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.most_recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>public_metrics.retweet_count</th>\n",
       "      <th>public_metrics.reply_count</th>\n",
       "      <th>public_metrics.like_count</th>\n",
       "      <th>public_metrics.quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1341896166171140103</td>\n",
       "      <td>2020-12-23T23:59:11.000Z</td>\n",
       "      <td>Every one of our district employees is an #ess...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1341895880853618688</td>\n",
       "      <td>2020-12-23T23:58:03.000Z</td>\n",
       "      <td>@DarraTheExplora Where would you inject the va...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1341895694085451776</td>\n",
       "      <td>2020-12-23T23:57:19.000Z</td>\n",
       "      <td>@thechrishan You might like this! \\n\\nAbout so...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1341895303297978373</td>\n",
       "      <td>2020-12-23T23:55:46.000Z</td>\n",
       "      <td>Post Vaccine Sex Fest new band name I call it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1341895270901149696</td>\n",
       "      <td>2020-12-23T23:55:38.000Z</td>\n",
       "      <td>What if instead of a vaccine we just were able...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1341555060891930627</td>\n",
       "      <td>2020-12-23T01:23:46.000Z</td>\n",
       "      <td>got the vaccine before the ps5, what a world h...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1341554906579275780</td>\n",
       "      <td>2020-12-23T01:23:09.000Z</td>\n",
       "      <td>There prioritizing conducted felons with the v...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1341554821858471942</td>\n",
       "      <td>2020-12-23T01:22:49.000Z</td>\n",
       "      <td>@JaniceDean Amen, Janice. I’m 72 with pulmonar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1341554805051940867</td>\n",
       "      <td>2020-12-23T01:22:45.000Z</td>\n",
       "      <td>@Khamarupa @TheRickyDavila What’s being critic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1341554779823235072</td>\n",
       "      <td>2020-12-23T01:22:39.000Z</td>\n",
       "      <td>I drank from a drinking fountain in O’Hara int...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                created_at  \\\n",
       "0     1341896166171140103  2020-12-23T23:59:11.000Z   \n",
       "1     1341895880853618688  2020-12-23T23:58:03.000Z   \n",
       "2     1341895694085451776  2020-12-23T23:57:19.000Z   \n",
       "3     1341895303297978373  2020-12-23T23:55:46.000Z   \n",
       "4     1341895270901149696  2020-12-23T23:55:38.000Z   \n",
       "...                   ...                       ...   \n",
       "1495  1341555060891930627  2020-12-23T01:23:46.000Z   \n",
       "1496  1341554906579275780  2020-12-23T01:23:09.000Z   \n",
       "1497  1341554821858471942  2020-12-23T01:22:49.000Z   \n",
       "1498  1341554805051940867  2020-12-23T01:22:45.000Z   \n",
       "1499  1341554779823235072  2020-12-23T01:22:39.000Z   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Every one of our district employees is an #ess...   \n",
       "1     @DarraTheExplora Where would you inject the va...   \n",
       "2     @thechrishan You might like this! \\n\\nAbout so...   \n",
       "3     Post Vaccine Sex Fest new band name I call it ...   \n",
       "4     What if instead of a vaccine we just were able...   \n",
       "...                                                 ...   \n",
       "1495  got the vaccine before the ps5, what a world h...   \n",
       "1496  There prioritizing conducted felons with the v...   \n",
       "1497  @JaniceDean Amen, Janice. I’m 72 with pulmonar...   \n",
       "1498  @Khamarupa @TheRickyDavila What’s being critic...   \n",
       "1499  I drank from a drinking fountain in O’Hara int...   \n",
       "\n",
       "      public_metrics.retweet_count  public_metrics.reply_count  \\\n",
       "0                                0                           0   \n",
       "1                                0                           0   \n",
       "2                                0                           1   \n",
       "3                                0                           0   \n",
       "4                                0                           1   \n",
       "...                            ...                         ...   \n",
       "1495                             0                           2   \n",
       "1496                             0                           1   \n",
       "1497                             0                           0   \n",
       "1498                             0                           0   \n",
       "1499                             0                           1   \n",
       "\n",
       "      public_metrics.like_count  public_metrics.quote_count  \n",
       "0                             0                           0  \n",
       "1                             1                           0  \n",
       "2                             1                           0  \n",
       "3                             0                           0  \n",
       "4                            10                           0  \n",
       "...                         ...                         ...  \n",
       "1495                          2                           0  \n",
       "1496                          0                           0  \n",
       "1497                          0                           0  \n",
       "1498                          0                           0  \n",
       "1499                          1                           0  \n",
       "\n",
       "[1500 rows x 7 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `searchtweets.ResultStream` not found.\n"
     ]
    }
   ],
   "source": [
    "??searchtweets.ResultStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "s = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2823.917551755905"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(time.time() - s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1623244061.923844"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-10-23T00:02:40.000Z'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(bla['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitterSearch",
   "language": "python",
   "name": "twittersearch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
