---
title: "NLP: ML-based"
output: html_notebook
---

## Reddit datasets
* Employment:
  * 1. Query: all
  * 2. Query: top 100 subreddits.
  * 3. Query: likely-to-be-relevant subreddits.
  * 4. No-query: all data from likely-to-be-relevant subreddits.
* Vaccination:
  * 1. Query: all
  
## Twitter datasets.
* Employment:
  * 1. Query: all
* Vaccination:
  * 1. Query: all



Cleaning stages.
1a:
* Remove useless columns
* Done in python scripts (Reddit/main and Twitter/main)

1b: 
* Remove any anomalies/useless posts missed by filters (e.g. blanks/removed/NaN, etc.)
* All lower-case.
* Tokenize
* Noise removal (punctuation, special characters, stopwords).

2:
* Stemming

```{r} 
source("ML_funcs.R", local = knitr::knit_global()) 
```


```{r}
twitter_emp_subset <- load_nlp_data('Twitter', 'Employment', level = 3, set = 1) %>% 
  filter(man_sentiment != -99) %>% 
  mutate(date = created_at) %>% 
  select(-created_at,
         -date)

twitter_emp_lex_c1b <- load_nlp_data('Twitter', 'Employment', level = 2, set = 1, stage = '1b')

twitter_emp_lex_c2 <- load_nlp_data('Twitter', 'Employment', level = 2, set = 1, stage = '2')
```

```{r}
c1b <- twitter_emp_lex_c1b %>%  
  inner_join(twitter_emp_subset) %>% 
  change_scores(.)

c2 <- twitter_emp_lex_c2 %>% 
  inner_join(twitter_emp_subset) %>% 
  change_scores(.)
```

```{r}
table(manual = c1b$man_sentiment, 
      bing = c1b$bing_score)

cor(c1b$man_sentiment, c1b$bing_score)
cor(c1b$man_sentiment, c1b$afinn_score)
cor(c1b$man_sentiment, c1b$nrc_score)

cor(c2$man_sentiment, c2$bing_score)
cor(c2$man_sentiment, c2$afinn_score)
cor(c2$man_sentiment, c2$nrc_score) 
``` 

```{r}
c1b <- c1b %>%  
  filter(man_sentiment != 0) %>% 
  mutate(man_sentiment = as.factor(man_sentiment),
         bing_score = as.factor(bing_score), 
         afinn_score = as.factor(afinn_score),
         nrc_score = as.factor(nrc_score)) 

c2 <- c2 %>% 
  filter(man_sentiment != 0) %>% 
  mutate(man_sentiment = as.factor(man_sentiment),
         bing_score = as.factor(bing_score),
         afinn_score = as.factor(afinn_score),
         nrc_score = as.factor(nrc_score))
``` 


## 1. Predictions based on orig features

* Lexicon scores + source + location
*!!NB: Not doing this anymore.

```{r}
# c1b_og <- c1b %>% 
#     select(bing_score,
#          afinn_score,
#          nrc_score,
#          source,
#          location,
#          man_sentiment)
# 
# 
# list[c1b_train_og, c1b_val_og] <- get_split(c1b_og)
# 
# nb <- train_nb(c1b_train_og, c1b_val_og)
# list[c1b_train_cm_og, c1b_val_cm_og] <- do_pred_nb(nb, c1b_train_og, c1b_val_og)
# 
# c1b_train_cm_og$overall[['Accuracy']]
# c1b_val_cm_og$overall[['Accuracy']]
```



## 2. Predictions based on text

* Using document term matrix

###C1

```{r}
# list[c1b_train_dtm_t, sparse_c1b_t] <- get_sparse_df(c1b, useMetrics = F)
# list[c1b_train_t, c1b_val_t] <- get_split(sparse_c1b_t)
# nb <- train_nb(c1b_train_t)
# list[c1b_train_cm_t, c1b_val_cm_t] <- do_pred_nb(nb, c1b_train_t, c1b_val_t)

```


```{r}
# list[c2_train_dtm_t, sparse_c2_t] <- get_sparse_df(c2, useMetrics = F)
# list[c2_train_t, c2_val_t] <- get_split(sparse_c2_t)
# nb <- train_nb(c2_train_t)
# list[c2_train_cm_t, c2_val_cm_t] <- do_pred_nb(nb, c2_train_t, c2_val_t)
```




```{r}
c1b_res <- train_classifiers(c1b, useMetrics = F)
c2_res <- train_classifiers(c2, useMetrics = F, nb = 2)
c2_res$classifiers$NB$cm$overall[['AccuracySD']] <- c1b_res$classifiers$NB$cm$overall[['AccuracySD']]
```


## 3. Predictions based on text + original features

* Using document term matrix + lexicon scores + source + location.

```{r}
# list[c1b_train_dtm_t_og, sparse_c1b_t_og] <- get_sparse_df(c1b, useMetrics = T)
# list[c1b_train_t_og, c1b_val_t_og] <- get_split(sparse_c1b_t_og)
# nb <- train_nb(c1b_train_t_og, c1b_val_t_og)
# list[c1b_train_cm_t_og, c1b_val_cm_t_og] <- do_pred_nb(nb, c1b_train_t_og, c1b_val_t_og)
# c1b_train_cm_t_og$overall[['Accuracy']]
# c1b_val_cm_t_og$overall[['Accuracy']]
```

```{r}
c1b_res_metrics <- train_classifiers(c1b, useMetrics=T)[1]
c2_res_metrics <- train_classifiers(c2, useMetrics=T, nb=2)

c2_res_metrics$classifiers$NB$cm$overall[['AccuracySD']] <- c1b_res_metrics$classifiers$NB$cm$overall[['AccuracySD']]
```

## Metrics

```{r}
perf <- list()
list[perf$c1b$table, perf$c1b$cm_plot] <- get_performance(c1b_res)
list[perf$c1b_metrics$table,perf$c1b_metrics$cm_plot] <- get_performance(c1b_res_metrics)
list[perf$c2$table, perf$c2$cm_plot] <- get_performance(c2_res)
list[perf$c2_metrics$table,perf$c2_metrics$cm_plot] <- get_performance(c2_res_metrics)

```


## Getting predictions for unseen data

```{r}

start <- Sys.time() 
c1b_pred <- do_pred_all(
  nb,
  twitter_emp_lex_c1b,
  train_dtm = c1b_train_dtm_t_og,
  useMetrics = T
)
end <- Sys.time()
(elapsed <- end - start) 
```









